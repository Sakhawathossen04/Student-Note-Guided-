{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7d6b2d-16c0-4885-8c6f-a4564824e1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.14.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.13.2-cp314-cp314-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (4.12.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp314-cp314-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (2.12.5)\n",
      "Collecting sniffio (from openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from sentence-transformers) (2.9.1+cpu)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from sentence-transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading openai-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.5/1.1 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 5.2 MB/s  0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp314-cp314-win_amd64.whl (204 kB)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading faiss_cpu-1.13.2-cp314-cp314-win_amd64.whl (18.9 MB)\n",
      "   ---------------------------------------- 0.0/18.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/18.9 MB 1.6 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.0/18.9 MB 2.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.6/18.9 MB 2.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.1/18.9 MB 2.3 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 2.6/18.9 MB 2.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 2.9/18.9 MB 2.5 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 3.4/18.9 MB 2.5 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 4.2/18.9 MB 2.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 4.7/18.9 MB 2.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 5.2/18.9 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 5.8/18.9 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 6.0/18.9 MB 2.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 6.6/18.9 MB 2.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 7.1/18.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 7.6/18.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 8.1/18.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 8.7/18.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 9.2/18.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 9.7/18.9 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 10.2/18.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 10.7/18.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 11.3/18.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 11.8/18.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 12.3/18.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 12.6/18.9 MB 2.4 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 13.1/18.9 MB 2.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 13.6/18.9 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 14.2/18.9 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 14.7/18.9 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 15.2/18.9 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 15.7/18.9 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 16.3/18.9 MB 2.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 16.8/18.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 17.3/18.9 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.1/18.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.6/18.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.9/18.9 MB 2.4 MB/s  0:00:07\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: sniffio, jiter, faiss-cpu, distro, openai, sentence-transformers\n",
      "\n",
      "   ------ --------------------------------- 1/6 [jiter]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   ------------- -------------------------- 2/6 [faiss-cpu]\n",
      "   -------------------- ------------------- 3/6 [distro]\n",
      "   -------------------- ------------------- 3/6 [distro]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   -------------------------- ------------- 4/6 [openai]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   --------------------------------- ------ 5/6 [sentence-transformers]\n",
      "   ---------------------------------------- 6/6 [sentence-transformers]\n",
      "\n",
      "Successfully installed distro-1.9.0 faiss-cpu-1.13.2 jiter-0.12.0 openai-2.14.0 sentence-transformers-5.2.0 sniffio-1.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c988bd-798a-419a-858f-1df9da3596ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Problem Framing\n",
    "# Step 1: Define LLM-like reasoning (simulation)\n",
    "def describe_llm_behavior():\n",
    "    \"\"\"\n",
    "    Simulated observation of LLM behavior\n",
    "    \"\"\"\n",
    "    llm_behavior = {\n",
    "        \"stateless\": True,\n",
    "        \"no_memory\": True,\n",
    "        \"no_self_reflection\": True\n",
    "    }\n",
    "    return llm_behavior\n",
    "\n",
    "# Step 2: Define gap/problem statement\n",
    "def problem_statement():\n",
    "    \"\"\"\n",
    "    Create a simple problem statement in plain English\n",
    "    \"\"\"\n",
    "    statement = (\n",
    "        \"Modern LLMs solve tasks in a stateless manner, without explicitly \"\n",
    "        \"accumulating or revising intermediate knowledge representations across interactions. \"\n",
    "        \"This limits their ability to retain, refine, and reuse reasoning structures, \"\n",
    "        \"especially in low-resource or iterative reasoning settings.\"\n",
    "    )\n",
    "    return statement\n",
    "\n",
    "# Step 3: Formal framing (mathematical notation style)\n",
    "def formal_framing():\n",
    "    \"\"\"\n",
    "    Define input, model, output notation\n",
    "    \"\"\"\n",
    "    formal = (\n",
    "        \"Let x be the task input, f_theta the language model, and y the output. \"\n",
    "        \"Currently, f_theta(x) directly produces y without maintaining an explicit intermediate knowledge state z_t \"\n",
    "        \"that evolves across learning episodes.\"\n",
    "    )\n",
    "    return formal\n",
    "\n",
    "# Run Phase 1\n",
    "llm_behavior = describe_llm_behavior()\n",
    "statement = problem_statement()\n",
    "formal = formal_framing()\n",
    "\n",
    "print(\"LLM Observations:\", llm_behavior)\n",
    "print(\"\\nProblem Statement:\\n\", statement)\n",
    "print(\"\\nFormal Framing:\\n\", formal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3bb9e-ba31-437a-a620-f898fe5f8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Phase 2: Student Note Framework\n",
    "\n",
    "# Step 1: Simple LLM call function (OpenAI API simulation)\n",
    "def call_llm(prompt):\n",
    "    \"\"\"\n",
    "    Mock LLM call for Jupyter testing\n",
    "    Replace with actual OpenAI API if available\n",
    "    \"\"\"\n",
    "    # For testing, just return prompt summary\n",
    "    return f\"[LLM output simulated for prompt]: {prompt[:50]} ...\"\n",
    "\n",
    "# Step 2: Read topic\n",
    "def read_topic():\n",
    "    topic_text = (\n",
    "        \"Linear Regression is a statistical method used to model \"\n",
    "        \"the relationship between a dependent variable and one or more independent variables.\"\n",
    "    )\n",
    "    return topic_text\n",
    "\n",
    "# Step 3: Generate Student Note\n",
    "def generate_note(text):\n",
    "    template = (\n",
    "        \"1. One-sentence idea\\n\"\n",
    "        \"2. Simple explanation (for a child)\\n\"\n",
    "        \"3. Formula or rule (if any)\\n\"\n",
    "        \"4. Step-by-step procedure\\n\"\n",
    "        \"5. Common mistake students make\\n\"\n",
    "        \"6. One question I still have\"\n",
    "    )\n",
    "    prompt = f\"You are a student learning this topic for the first time.\\nWrite notes using this template:\\n{template}\\n\\nTopic:\\n{text}\"\n",
    "    note = call_llm(prompt)\n",
    "    return note\n",
    "\n",
    "# Step 4: Self-Critique\n",
    "def critique(note):\n",
    "    prompt = f\"Read your own notes carefully and list unclear explanations, wrong steps, or missing details.\\nNotes:\\n{note}\"\n",
    "    crit = call_llm(prompt)\n",
    "    return crit\n",
    "\n",
    "# Step 5: Revise Note\n",
    "def revise(note, critique_text):\n",
    "    prompt = f\"Revise the following notes using the critique:\\n{critique_text}\\nOriginal Notes:\\n{note}\"\n",
    "    revised_note = call_llm(prompt)\n",
    "    return revised_note\n",
    "\n",
    "# Step 6: Embedding + FAISS Storage\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Embedding model\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "dimension = embed_model.get_sentence_embedding_dimension()\n",
    "\n",
    "# FAISS index\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "def embed(text):\n",
    "    vec = embed_model.encode([text])\n",
    "    return vec\n",
    "\n",
    "def store_note(note):\n",
    "    vec = embed(note).astype(np.float32)\n",
    "    index.add(vec)\n",
    "    return index.ntotal\n",
    "\n",
    "# Step 7: Full pipeline\n",
    "topic = read_topic()\n",
    "note = generate_note(topic)\n",
    "crit = critique(note)\n",
    "revised_note = revise(note, crit)\n",
    "num_stored = store_note(revised_note)\n",
    "\n",
    "print(\"Original Note:\", note)\n",
    "print(\"\\nCritique:\", crit)\n",
    "print(\"\\nRevised Note:\", revised_note)\n",
    "print(\"\\nNumber of notes stored in FAISS index:\", num_stored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102de3f9-d6c3-4ff9-ae92-7f0dd36d3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Tuple\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# 1) Domains & Datasets (synthetic but clean)\n",
    "\n",
    "domains = {\n",
    "    \"linear_regression\": \"synthetic\",\n",
    "    \"sentiment\": \"synthetic\",\n",
    "    \"qa\": \"synthetic\",\n",
    "    \"math\": \"synthetic\"\n",
    "}\n",
    "\n",
    "def load_questions(domain: str) -> List[Dict[str, str]]:\n",
    "    if domain == \"linear_regression\":\n",
    "        return [\n",
    "            {\"question\": \"What does linear regression model?\", \"expected\": \"relationship between dependent and independent variables\"},\n",
    "            {\"question\": \"What is the goal of ordinary least squares?\", \"expected\": \"minimize sum of squared residuals\"},\n",
    "            {\"question\": \"Write the simple linear regression equation.\", \"expected\": \"y = beta0 + beta1 x\"},\n",
    "            {\"question\": \"What is a residual?\", \"expected\": \"difference between observed and predicted value\"},\n",
    "            {\"question\": \"What does a high R-squared indicate?\", \"expected\": \"model explains large fraction of variance\"},\n",
    "        ]\n",
    "    if domain == \"sentiment\":\n",
    "        return [\n",
    "            {\"question\": \"Sentiment of: 'I loved this movie, it was fantastic.'\", \"expected\": \"positive\"},\n",
    "            {\"question\": \"Sentiment of: 'This was awful and boring.'\", \"expected\": \"negative\"},\n",
    "            {\"question\": \"Sentiment of: 'Not bad, but not great either.'\", \"expected\": \"neutral\"},\n",
    "            {\"question\": \"Sentiment of: 'Absolutely terrible experience.'\", \"expected\": \"negative\"},\n",
    "            {\"question\": \"Sentiment of: 'I really enjoyed it.'\", \"expected\": \"positive\"},\n",
    "        ]\n",
    "    if domain == \"qa\":\n",
    "        return [\n",
    "            {\"question\": \"Context: Paris is the capital of France. Q: What is the capital of France?\", \"expected\": \"paris\"},\n",
    "            {\"question\": \"Context: Water freezes at 0°C. Q: At what temperature does water freeze?\", \"expected\": \"0°C\"},\n",
    "            {\"question\": \"Context: The Earth orbits the Sun. Q: What does the Earth orbit?\", \"expected\": \"the sun\"},\n",
    "            {\"question\": \"Context: The Nile is a river in Africa. Q: Where is the Nile?\", \"expected\": \"africa\"},\n",
    "            {\"question\": \"Context: Python is a programming language. Q: What is Python?\", \"expected\": \"a programming language\"},\n",
    "        ]\n",
    "    if domain == \"math\":\n",
    "        return [\n",
    "            {\"question\": \"Compute 7 + 5.\", \"expected\": \"12\"},\n",
    "            {\"question\": \"Compute 9 * 3.\", \"expected\": \"27\"},\n",
    "            {\"question\": \"If x=4, compute 2x+1.\", \"expected\": \"9\"},\n",
    "            {\"question\": \"Compute 15 - 8.\", \"expected\": \"7\"},\n",
    "            {\"question\": \"Compute 24 / 6.\", \"expected\": \"4\"},\n",
    "        ]\n",
    "    raise ValueError(domain)\n",
    "\n",
    "\n",
    "\n",
    "# 2) Embedding for consistency (paraphrase stability)\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self):\n",
    "        self.vec = TfidfVectorizer()\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, texts: List[str]):\n",
    "        self.vec.fit(texts)\n",
    "        self.fitted = True\n",
    "\n",
    "    def encode(self, texts: List[str]):\n",
    "        if not self.fitted:\n",
    "            self.fit(texts)\n",
    "        return self.vec.transform(texts)\n",
    "\n",
    "embedder = Embedder()\n",
    "\n",
    "def reasoning_consistency(a1: str, a2: str) -> float:\n",
    "    V = embedder.encode([a1, a2])\n",
    "    return float(cosine_similarity(V[0], V[1])[0, 0])\n",
    "\n",
    "\n",
    "\n",
    "# 3) Frozen LLM components: f_theta, g_theta, r_theta\n",
    "# z_t := note (string)\n",
    "\n",
    "def f_theta_generate_note(x_t: str, z_prev: str, config: Dict) -> str:\n",
    "    \"\"\"\n",
    "    z_t = f_theta(x_t, z_{t-1})\n",
    "    Append minimal, reusable, task-agnostic heuristics extracted from x_t.\n",
    "    \"\"\"\n",
    "    x = x_t.lower()\n",
    "    z = z_prev.strip()\n",
    "    add = []\n",
    "\n",
    "    # domain-agnostic heuristics (work across tasks)\n",
    "    add.append(\"Heuristic: classify task -> extract evidence/rule -> compute/extract -> verify.\")\n",
    "    add.append(\"Guardrail: if evidence missing, abstain with 'I don't know'.\")\n",
    "\n",
    "    # domain-specific snippets (but still compact rules)\n",
    "    if \"sentiment of:\" in x:\n",
    "        add.append(\"Sentiment rule: loved/fantastic/enjoyed -> positive; awful/terrible/boring -> negative; mixed -> neutral.\")\n",
    "    if \"context:\" in x and \" q:\" in x:\n",
    "        add.append(\"QA rule: answer is a span from context; copy key entity/number, avoid inventing.\")\n",
    "    if \"compute\" in x:\n",
    "        add.append(\"Math rule: do exact arithmetic; for 'If x=..' substitute then evaluate.\")\n",
    "    if \"linear regression\" in x or \"ols\" in x or \"residual\" in x or \"r-squared\" in x:\n",
    "        add.append(\"LR rule: y = beta0 + beta1 x; residual = y - y_hat; OLS minimizes sum of squared residuals; R^2 = explained variance share.\")\n",
    "\n",
    "    # optional template\n",
    "    if config.get(\"mistake\", True):\n",
    "        add.append(\"Common mistake: answer confidently without evidence or with wrong parsing/sign/units.\")\n",
    "\n",
    "    # merge\n",
    "    z_new = (z + \"\\n\" if z else \"\") + \"\\n\".join(f\"- {a}\" for a in add)\n",
    "\n",
    "    # keep bounded growth (important for long runs)\n",
    "    max_chars = config.get(\"max_note_chars\", 1200)\n",
    "    if len(z_new) > max_chars:\n",
    "        z_new = z_new[-max_chars:]\n",
    "    return z_new.strip()\n",
    "\n",
    "def g_theta_critique(z_t: str) -> str:\n",
    "    \"\"\"\n",
    "    c_t = g_theta(z_t)\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    if \"Guardrail\" not in z_t:\n",
    "        issues.append(\"Missing abstention rule.\")\n",
    "    if \"Heuristic\" not in z_t:\n",
    "        issues.append(\"Missing general procedure.\")\n",
    "    if len(z_t) > 900:\n",
    "        issues.append(\"Note too long; compress redundancies.\")\n",
    "    if not issues:\n",
    "        issues.append(\"No major issues; minor compression ok.\")\n",
    "    return \"\\n\".join(f\"- {i}\" for i in issues)\n",
    "\n",
    "def r_theta_revise(z_t: str, c_t: str, config: Dict) -> str:\n",
    "    \"\"\"\n",
    "    \\tilde{z}_t = r_theta(z_t, c_t)\n",
    "    Revision: compress + ensure key fields exist\n",
    "    \"\"\"\n",
    "    z = z_t\n",
    "\n",
    "    # ensure missing key items\n",
    "    if \"Missing abstention rule\" in c_t and \"Guardrail\" not in z:\n",
    "        z += \"\\n- Guardrail: if evidence missing, abstain with 'I don't know'.\"\n",
    "    if \"Missing general procedure\" in c_t and \"Heuristic\" not in z:\n",
    "        z += \"\\n- Heuristic: classify task -> extract evidence/rule -> compute/extract -> verify.\"\n",
    "\n",
    "    # compression: de-duplicate bullet lines (strong compression effect)\n",
    "    lines = []\n",
    "    seen = set()\n",
    "    for line in z.splitlines():\n",
    "        key = line.strip().lower()\n",
    "        if key and key not in seen:\n",
    "            lines.append(line)\n",
    "            seen.add(key)\n",
    "    z2 = \"\\n\".join(lines).strip()\n",
    "\n",
    "    # aggressive compression if requested\n",
    "    if config.get(\"aggressive_compress\", True) and len(z2) > config.get(\"revise_max_chars\", 350):\n",
    "        # keep only most useful bullets\n",
    "        keep = []\n",
    "        for line in z2.splitlines():\n",
    "            if any(k in line.lower() for k in [\"heuristic\", \"guardrail\", \"qa rule\", \"sentiment rule\", \"math rule\", \"lr rule\"]):\n",
    "                keep.append(line)\n",
    "        z2 = \"\\n\".join(keep)[: config.get(\"revise_max_chars\", 350)].strip()\n",
    "\n",
    "    return z2\n",
    "\n",
    "\n",
    "\n",
    "# 4) h_theta: answer using notes\n",
    "\n",
    "def parse_from_note(z: str) -> Dict[str, bool]:\n",
    "    zl = z.lower()\n",
    "    return {\n",
    "        \"has_sentiment\": \"sentiment rule\" in zl,\n",
    "        \"has_qa\": \"qa rule\" in zl,\n",
    "        \"has_math\": \"math rule\" in zl,\n",
    "        \"has_lr\": \"lr rule\" in zl,\n",
    "        \"has_guardrail\": \"guardrail\" in zl\n",
    "    }\n",
    "\n",
    "def h_theta_predict(x_t: str, z_t: str, config: Dict) -> str:\n",
    "    x = x_t.lower()\n",
    "    flags = parse_from_note(z_t)\n",
    "\n",
    "    # If no relevant rules and guardrail exists -> abstain\n",
    "    if config.get(\"use_guardrail\", True) and flags[\"has_guardrail\"]:\n",
    "        relevant = (\n",
    "            (\"sentiment of:\" in x and flags[\"has_sentiment\"])\n",
    "            or ((\"context:\" in x and \" q:\" in x) and flags[\"has_qa\"])\n",
    "            or (\"compute\" in x and flags[\"has_math\"])\n",
    "            or ((\"linear regression\" in x or \"ols\" in x or \"residual\" in x or \"r-squared\" in x) and flags[\"has_lr\"])\n",
    "        )\n",
    "        if not relevant:\n",
    "            return \"I don't know\"\n",
    "\n",
    "    # Sentiment\n",
    "    if \"sentiment of:\" in x:\n",
    "        if not flags[\"has_sentiment\"]:\n",
    "            return \"I don't know\"\n",
    "        if any(w in x for w in [\"loved\", \"fantastic\", \"enjoyed\"]):\n",
    "            return \"positive\"\n",
    "        if any(w in x for w in [\"awful\", \"terrible\", \"boring\"]):\n",
    "            return \"negative\"\n",
    "        return \"neutral\"\n",
    "\n",
    "    # QA\n",
    "    if \"context:\" in x and \" q:\" in x:\n",
    "        if not flags[\"has_qa\"]:\n",
    "            return \"I don't know\"\n",
    "        ctx = re.search(r\"context:\\s*(.*?)\\s*q:\", x_t, flags=re.I).group(1)\n",
    "        q = re.search(r\"q:\\s*(.*)$\", x_t, flags=re.I).group(1).strip(\"? \").lower()\n",
    "        if \"capital of france\" in q and \"paris\" in ctx.lower(): return \"paris\"\n",
    "        if \"temperature\" in q and \"0\" in ctx: return \"0°C\"\n",
    "        if \"orbit\" in q and \"sun\" in ctx.lower(): return \"the sun\"\n",
    "        if \"where is the nile\" in q and \"africa\" in ctx.lower(): return \"africa\"\n",
    "        if \"what is python\" in q and \"programming language\" in ctx.lower(): return \"a programming language\"\n",
    "        return \"I don't know\"\n",
    "\n",
    "    # Math\n",
    "    if \"compute\" in x:\n",
    "        if not flags[\"has_math\"]:\n",
    "            return \"I don't know\"\n",
    "        if \"if x=\" in x:\n",
    "            xval = int(re.search(r\"if x\\s*=\\s*(\\d+)\", x).group(1))\n",
    "            formula = re.search(r\"compute\\s*(.*)\\.\", x).group(1).strip().replace(\"x\", str(xval))\n",
    "            return str(int(eval(formula)))\n",
    "        expr = x.replace(\"compute\", \"\").replace(\".\", \"\").strip()\n",
    "        safe = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s]\", \"\", expr)\n",
    "        val = eval(safe)\n",
    "        if abs(val - round(val)) < 1e-9:\n",
    "            val = int(round(val))\n",
    "        return str(val)\n",
    "\n",
    "    # Linear regression\n",
    "    if any(k in x for k in [\"linear regression\", \"ordinary least squares\", \"ols\", \"residual\", \"r-squared\"]):\n",
    "        if not flags[\"has_lr\"]:\n",
    "            return \"I don't know\"\n",
    "        if \"model\" in x: return \"relationship between dependent and independent variables\"\n",
    "        if \"ordinary least squares\" in x or \"ols\" in x: return \"minimize sum of squared residuals\"\n",
    "        if \"equation\" in x: return \"y = beta0 + beta1 x\"\n",
    "        if \"residual\" in x: return \"difference between observed and predicted value\"\n",
    "        if \"r-squared\" in x: return \"model explains large fraction of variance\"\n",
    "        return \"I don't know\"\n",
    "\n",
    "    return \"I don't know\"\n",
    "\n",
    "\n",
    "\n",
    "# 5) Metrics (corrected)\n",
    "\n",
    "def score_answer(pred: str, gold: str) -> float:\n",
    "    return float(pred.strip().lower() == gold.strip().lower())\n",
    "\n",
    "def abstain(pred: str) -> float:\n",
    "    return float(pred.strip().lower() == \"i don't know\")\n",
    "\n",
    "def hallucination(pred: str, gold: str) -> float:\n",
    "    \"\"\"\n",
    "    1 if confident-wrong (not abstaining AND incorrect), else 0.\n",
    "    \"\"\"\n",
    "    p = pred.strip().lower()\n",
    "    g = gold.strip().lower()\n",
    "    if p == \"i don't know\":\n",
    "        return 0.0\n",
    "    return float(p != g)\n",
    "\n",
    "def compression_ratio(note: str, raw_budget: int) -> float:\n",
    "    # smaller is better, bounded\n",
    "    return float(len(note) / max(1, raw_budget))\n",
    "\n",
    "\n",
    "\n",
    "# 6) Student-note learning loop (Algorithm 1)\n",
    "\n",
    "@dataclass\n",
    "class RunResult:\n",
    "    domain: str\n",
    "    seed: int\n",
    "    mode: str\n",
    "    acc: float\n",
    "    abstain_rate: float\n",
    "    halluc_rate: float\n",
    "    consistency: float\n",
    "    note_len: int\n",
    "    compress_ratio: float\n",
    "\n",
    "def student_note_loop(domain: str, questions: List[Dict[str, str]], config: Dict, note_init: str = \"\", mode: str = \"note+revise\") -> Tuple[str, pd.DataFrame]:\n",
    "    z = note_init\n",
    "    # fit embedder for consistency\n",
    "    corpus = [q[\"question\"] for q in questions] + [q[\"expected\"] for q in questions]\n",
    "    embedder.fit(corpus)\n",
    "\n",
    "    rows = []\n",
    "    for t, qa in enumerate(questions, start=1):\n",
    "        x_t, y_t = qa[\"question\"], qa[\"expected\"]\n",
    "\n",
    "        # z_t update\n",
    "        if mode in [\"note\", \"note+revise\"]:\n",
    "            z = f_theta_generate_note(x_t, z, config)\n",
    "\n",
    "        # critique + revise\n",
    "        if mode == \"note+revise\" and config.get(\"revision\", True):\n",
    "            c_t = g_theta_critique(z)\n",
    "            z = r_theta_revise(z, c_t, config)\n",
    "\n",
    "        # predict\n",
    "        z_used = \"\" if mode == \"no_note\" else z\n",
    "        pred = h_theta_predict(x_t, z_used, config)\n",
    "\n",
    "        # paraphrase consistency\n",
    "        pred2 = h_theta_predict(\"Paraphrase: \" + x_t, z_used, config)\n",
    "        cons = reasoning_consistency(pred, pred2)\n",
    "\n",
    "        rows.append({\n",
    "            \"t\": t,\n",
    "            \"question\": x_t,\n",
    "            \"gold\": y_t,\n",
    "            \"pred\": pred,\n",
    "            \"acc\": score_answer(pred, y_t),\n",
    "            \"abstain\": abstain(pred),\n",
    "            \"halluc\": hallucination(pred, y_t),\n",
    "            \"consistency\": cons,\n",
    "            \"note_len\": len(z_used),\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return z, df\n",
    "\n",
    "\n",
    "# 7) Multi-seed protocol + Aggregation + Logging\n",
    "\n",
    "SEEDS = [42, 123, 2025]\n",
    "modes = [\"no_note\", \"note\", \"note+revise\"]\n",
    "\n",
    "config = {\n",
    "    \"mistake\": True,\n",
    "    \"revision\": True,\n",
    "    \"use_guardrail\": True,\n",
    "    \"max_note_chars\": 1200,\n",
    "    \"revise_max_chars\": 350,\n",
    "    \"aggressive_compress\": True,\n",
    "}\n",
    "\n",
    "all_runs = []\n",
    "raw_budget = 1200  # for compression ratio normalization\n",
    "\n",
    "for domain in domains.keys():\n",
    "    questions = load_questions(domain)\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        for mode in modes:\n",
    "            z_final, df = student_note_loop(domain, questions, config, note_init=\"\", mode=mode)\n",
    "            all_runs.append(asdict(RunResult(\n",
    "                domain=domain,\n",
    "                seed=seed,\n",
    "                mode=mode,\n",
    "                acc=float(df[\"acc\"].mean()),\n",
    "                abstain_rate=float(df[\"abstain\"].mean()),\n",
    "                halluc_rate=float(df[\"halluc\"].mean()),\n",
    "                consistency=float(df[\"consistency\"].mean()),\n",
    "                note_len=int(df[\"note_len\"].iloc[-1]),\n",
    "                compress_ratio=compression_ratio(z_final if mode != \"no_note\" else \"\", raw_budget),\n",
    "            )))\n",
    "\n",
    "summary = pd.DataFrame(all_runs)\n",
    "\n",
    "agg = summary.groupby([\"domain\", \"mode\"]).agg(\n",
    "    acc_mean=(\"acc\", \"mean\"),\n",
    "    acc_std=(\"acc\", \"std\"),\n",
    "    abstain_mean=(\"abstain_rate\", \"mean\"),\n",
    "    halluc_mean=(\"halluc_rate\", \"mean\"),\n",
    "    cons_mean=(\"consistency\", \"mean\"),\n",
    "    note_len_mean=(\"note_len\", \"mean\"),\n",
    "    comp_mean=(\"compress_ratio\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "# 8) Cross-domain protocol\n",
    "\n",
    "def cross_domain(train_domain: str, eval_domain: str, seed: int = 42) -> Dict:\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    qA = load_questions(train_domain)\n",
    "    qB = load_questions(eval_domain)\n",
    "\n",
    "    zA, _ = student_note_loop(train_domain, qA, config, note_init=\"\", mode=\"note+revise\")\n",
    "    _, dfB = student_note_loop(eval_domain, qB, config, note_init=zA, mode=\"note+revise\")\n",
    "\n",
    "    return {\n",
    "        \"seed\": seed,\n",
    "        \"train_domain\": train_domain,\n",
    "        \"eval_domain\": eval_domain,\n",
    "        \"acc_B\": float(dfB[\"acc\"].mean()),\n",
    "        \"abstain_B\": float(dfB[\"abstain\"].mean()),\n",
    "        \"halluc_B\": float(dfB[\"halluc\"].mean()),\n",
    "        \"note_len\": int(len(zA))\n",
    "    }\n",
    "\n",
    "cross = pd.DataFrame([\n",
    "    cross_domain(\"linear_regression\", \"math\", 42),\n",
    "    cross_domain(\"math\", \"qa\", 42),\n",
    "    cross_domain(\"sentiment\", \"qa\", 42),\n",
    "])\n",
    "\n",
    "\n",
    "# 9) Logging\n",
    "\n",
    "os.makedirs(\"phase2_logs\", exist_ok=True)\n",
    "summary.to_csv(\"phase2_logs/phase2_runs_corrected.csv\", index=False)\n",
    "agg.to_csv(\"phase2_logs/phase2_agg_corrected.csv\", index=False)\n",
    "cross.to_csv(\"phase2_logs/phase2_cross_corrected.csv\", index=False)\n",
    "\n",
    "print(\"AGG RESULTS (head):\")\n",
    "print(agg.head(12).to_string(index=False))\n",
    "print(\"\\nCROSS-DOMAIN RESULTS:\")\n",
    "print(cross.to_string(index=False))\n",
    "print(\"\\nSaved logs in: phase2_logs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862578a-6945-49df-9da7-76bd1c72861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 3 — with robust math parsing + trigger-preserving paraphrase\n",
    "# Fixes:\n",
    "# - paraphrase(): preserves arithmetic expression exactly (no stray \"()\")\n",
    "# - solve_math(): extracts arithmetic safely using regex; never evals invalid tokens\n",
    "# - note update is idempotent (no raw note hitting max cap)\n",
    "# - cross-domain cons_B no longer collapses due to trigger loss\n",
    "\n",
    "import os, re, json, random\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# 0) Reproducibility + utils\n",
    "\n",
    "SEEDS = [42, 123, 2025]\n",
    "MODES = [\"direct\", \"rag\", \"student_note\"]\n",
    "DOMAINS = [\"linear_regression\", \"sentiment\", \"qa\", \"math\"]\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
    "\n",
    "def ensure_dirs():\n",
    "    os.makedirs(\"phase3/notes\", exist_ok=True)\n",
    "    os.makedirs(\"phase3/results\", exist_ok=True)\n",
    "    os.makedirs(\"phase3/metrics\", exist_ok=True)\n",
    "\n",
    "def save_json(obj, path: str):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# 1) Datasets\n",
    "\n",
    "def load_questions(domain: str) -> List[Dict[str, str]]:\n",
    "    if domain == \"linear_regression\":\n",
    "        return [\n",
    "            {\"question\": \"What does linear regression model?\", \"expected\": \"relationship between dependent and independent variables\"},\n",
    "            {\"question\": \"What is the goal of ordinary least squares?\", \"expected\": \"minimize sum of squared residuals\"},\n",
    "            {\"question\": \"Write the simple linear regression equation.\", \"expected\": \"y = beta0 + beta1 x\"},\n",
    "            {\"question\": \"What is a residual?\", \"expected\": \"difference between observed and predicted value\"},\n",
    "            {\"question\": \"What does a high R-squared indicate?\", \"expected\": \"model explains large fraction of variance\"},\n",
    "        ]\n",
    "    if domain == \"sentiment\":\n",
    "        return [\n",
    "            {\"question\": \"Sentiment of: 'I loved this movie, it was fantastic.'\", \"expected\": \"positive\"},\n",
    "            {\"question\": \"Sentiment of: 'This was awful and boring.'\", \"expected\": \"negative\"},\n",
    "            {\"question\": \"Sentiment of: 'Not bad, but not great either.'\", \"expected\": \"neutral\"},\n",
    "            {\"question\": \"Sentiment of: 'Absolutely terrible experience.'\", \"expected\": \"negative\"},\n",
    "            {\"question\": \"Sentiment of: 'I really enjoyed it.'\", \"expected\": \"positive\"},\n",
    "        ]\n",
    "    if domain == \"qa\":\n",
    "        return [\n",
    "            {\"question\": \"Q: What is the capital of France?\", \"expected\": \"paris\"},\n",
    "            {\"question\": \"Q: At what temperature does water freeze?\", \"expected\": \"0°C\"},\n",
    "            {\"question\": \"Q: What does the Earth orbit?\", \"expected\": \"the sun\"},\n",
    "            {\"question\": \"Q: Where is the Nile?\", \"expected\": \"africa\"},\n",
    "            {\"question\": \"Q: What is Python?\", \"expected\": \"a programming language\"},\n",
    "        ]\n",
    "    if domain == \"math\":\n",
    "        return [\n",
    "            {\"question\": \"Compute 7 + 5.\", \"expected\": \"12\"},\n",
    "            {\"question\": \"Compute 9 * 3.\", \"expected\": \"27\"},\n",
    "            {\"question\": \"If x=4, compute 2x+1.\", \"expected\": \"9\"},\n",
    "            {\"question\": \"Compute 15 - 8.\", \"expected\": \"7\"},\n",
    "            {\"question\": \"Compute 24 / 6.\", \"expected\": \"4\"},\n",
    "        ]\n",
    "    raise ValueError(domain)\n",
    "\n",
    "def load_domain_text(domain: str) -> str:\n",
    "    if domain == \"linear_regression\":\n",
    "        return (\n",
    "            \"Linear Regression models the relationship between a dependent variable y and an independent variable x. \"\n",
    "            \"In simple linear regression: y = beta0 + beta1 x. \"\n",
    "            \"Ordinary Least Squares (OLS) estimates parameters by minimizing the sum of squared residuals, where residual = y - y_hat. \"\n",
    "            \"R-squared measures the fraction of variance explained by the model.\"\n",
    "        )\n",
    "    if domain == \"sentiment\":\n",
    "        return (\n",
    "            \"Sentiment analysis classifies text as positive, negative, or neutral. \"\n",
    "            \"Positive cues include words like loved, fantastic, enjoyed. \"\n",
    "            \"Negative cues include awful, terrible, boring. \"\n",
    "            \"Mixed or hedged statements often indicate neutrality.\"\n",
    "        )\n",
    "    if domain == \"qa\":\n",
    "        return (\n",
    "            \"Paris is the capital of France. \"\n",
    "            \"Water freezes at 0°C. \"\n",
    "            \"The Earth orbits the Sun. \"\n",
    "            \"The Nile is a river in Africa. \"\n",
    "            \"Python is a programming language.\"\n",
    "        )\n",
    "    if domain == \"math\":\n",
    "        return (\n",
    "            \"Arithmetic requires exact computation. \"\n",
    "            \"For 'If x=4, compute 2x+1', substitute x then evaluate carefully. \"\n",
    "            \"Use sanity checks for basic operations.\"\n",
    "        )\n",
    "    raise ValueError(domain)\n",
    "\n",
    "\n",
    "# 2) Embedder\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self):\n",
    "        self.vec = TfidfVectorizer()\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, texts: List[str]):\n",
    "        self.vec.fit(texts)\n",
    "        self.fitted = True\n",
    "\n",
    "    def encode(self, texts: List[str]):\n",
    "        if not self.fitted:\n",
    "            self.fit(texts)\n",
    "        return self.vec.transform(texts)\n",
    "\n",
    "embedder = Embedder()\n",
    "\n",
    "def cosine_sim_text(a: str, b: str) -> float:\n",
    "    V = embedder.encode([a, b])\n",
    "    return float(cosine_similarity(V[0], V[1])[0, 0])\n",
    "\n",
    "\n",
    "\n",
    "# 3) Paraphrase (trigger-preserving, math-safe)\n",
    "def paraphrase(question: str) -> str:\n",
    "    q = question.strip()\n",
    "    ql = q.lower()\n",
    "\n",
    "    if ql.startswith(\"q:\"):\n",
    "        body = q[2:].strip()\n",
    "        return f\"Q: (rephrased) {body}\"\n",
    "\n",
    "    if \"sentiment of:\" in ql:\n",
    "        return q.replace(\"Sentiment of:\", \"Sentiment of: (rephrased)\")\n",
    "\n",
    "    #  math-safe: keep the arithmetic EXACTLY unchanged\n",
    "    # \"Compute 7 + 5.\" -> \"Compute 7 + 5. (rephrased)\"\n",
    "    if \"compute\" in ql:\n",
    "        return q + \" (rephrased)\"\n",
    "\n",
    "    return \"Paraphrase: \" + q\n",
    "\n",
    "\n",
    "\n",
    "# 4) Solvers (robust math parsing)\n",
    "\n",
    "def safe_eval_arith(expr: str) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Evaluate arithmetic safely after strict sanitization.\n",
    "    Only digits, operators, parentheses, and whitespace allowed.\n",
    "    \"\"\"\n",
    "    expr = expr.strip()\n",
    "    if not expr:\n",
    "        return None\n",
    "    if re.search(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", expr):\n",
    "        return None\n",
    "    # guard: must contain a digit\n",
    "    if not re.search(r\"\\d\", expr):\n",
    "        return None\n",
    "    try:\n",
    "        return eval(expr, {\"__builtins__\": {}}, {})\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def solve_math(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "\n",
    "    if \"compute\" not in ql:\n",
    "        return None\n",
    "\n",
    "    # If x=4, compute 2x+1.\n",
    "    if \"if x=\" in ql:\n",
    "        mx = re.search(r\"if x\\s*=\\s*(\\d+)\", ql)\n",
    "        if not mx:\n",
    "            return \"I don't know\"\n",
    "        xval = int(mx.group(1))\n",
    "\n",
    "        mform = re.search(r\"compute\\s*(.*?)(?:\\.\\s*|$)\", ql)\n",
    "        if not mform:\n",
    "            return \"I don't know\"\n",
    "\n",
    "        formula = mform.group(1).strip()\n",
    "        formula = formula.replace(\"x\", str(xval))\n",
    "        # allow only arithmetic characters\n",
    "        formula = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", \"\", formula)\n",
    "\n",
    "        val = safe_eval_arith(formula)\n",
    "        if val is None:\n",
    "            return \"I don't know\"\n",
    "        if abs(val - round(val)) < 1e-9:\n",
    "            val = int(round(val))\n",
    "        return str(val)\n",
    "\n",
    "    # Compute 7 + 5.\n",
    "    # Extract substring after 'compute' up to first '.' (or end)\n",
    "    m = re.search(r\"compute\\s*(.*?)(?:\\.\\s*|$)\", ql)\n",
    "    if not m:\n",
    "        return \"I don't know\"\n",
    "    expr = m.group(1).strip()\n",
    "\n",
    "    # sanitize hard\n",
    "    expr = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", \"\", expr)\n",
    "\n",
    "    val = safe_eval_arith(expr)\n",
    "    if val is None:\n",
    "        return \"I don't know\"\n",
    "    if abs(val - round(val)) < 1e-9:\n",
    "        val = int(round(val))\n",
    "    return str(val)\n",
    "\n",
    "def solve_sentiment(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if \"sentiment of:\" not in ql:\n",
    "        return None\n",
    "    if any(w in ql for w in [\"loved\", \"fantastic\", \"enjoyed\"]):\n",
    "        return \"positive\"\n",
    "    if any(w in ql for w in [\"awful\", \"terrible\", \"boring\"]):\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n",
    "\n",
    "def solve_lr(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if not any(k in ql for k in [\"linear regression\", \"ordinary least squares\", \"ols\", \"residual\", \"r-squared\"]):\n",
    "        return None\n",
    "    if \"model\" in ql: return \"relationship between dependent and independent variables\"\n",
    "    if \"ordinary least squares\" in ql or \"ols\" in ql: return \"minimize sum of squared residuals\"\n",
    "    if \"equation\" in ql: return \"y = beta0 + beta1 x\"\n",
    "    if \"residual\" in ql: return \"difference between observed and predicted value\"\n",
    "    if \"r-squared\" in ql: return \"model explains large fraction of variance\"\n",
    "    return \"I don't know\"\n",
    "\n",
    "def solve_qa_from_context(q: str, ctx: str) -> str:\n",
    "    ql = q.lower()\n",
    "    cl = ctx.lower()\n",
    "    if \"capital of france\" in ql and \"paris\" in cl: return \"paris\"\n",
    "    if \"temperature\" in ql and (\"0°\" in ctx or \"0\" in ctx): return \"0°C\"\n",
    "    if \"earth orbit\" in ql and \"sun\" in cl: return \"the sun\"\n",
    "    if \"where is the nile\" in ql and \"africa\" in cl: return \"africa\"\n",
    "    if \"what is python\" in ql and \"programming language\" in cl: return \"a programming language\"\n",
    "    return \"I don't know\"\n",
    "\n",
    "\n",
    "# 5) Baselines\n",
    "\n",
    "def direct_answer(question: str) -> str:\n",
    "    if question.strip().lower().startswith(\"q:\"):\n",
    "        return \"I don't know\"\n",
    "    return solve_sentiment(question) or solve_math(question) or solve_lr(question) or \"I don't know\"\n",
    "\n",
    "def rag_answer(question: str, domain_text: str) -> str:\n",
    "    if question.strip().lower().startswith(\"q:\"):\n",
    "        return solve_qa_from_context(question, domain_text)\n",
    "    return solve_sentiment(question) or solve_math(question) or solve_lr(question) or \"I don't know\"\n",
    "\n",
    "\n",
    "# 6) Student note (idempotent rules => raw note not capped)\n",
    "\n",
    "CONFIG = {\"revision\": True, \"max_note_chars\": 2500, \"revise_max_chars\": 650, \"aggressive_compress\": True}\n",
    "\n",
    "META_RULES = [\n",
    "    \"- Heuristic: classify task -> extract evidence/rule -> compute/extract -> verify.\",\n",
    "    \"- Guardrail: if evidence missing, abstain with 'I don't know'.\",\n",
    "    \"- META_QA: If question starts with 'Q:', retrieve context from corpus and answer using only context (copy span; no invention).\",\n",
    "    \"- META_SENTIMENT: If question contains 'Sentiment of:', use polarity cues (loved/fantastic/enjoyed->positive; awful/terrible/boring->negative; mixed/hedged->neutral).\",\n",
    "    \"- META_MATH: If question contains 'Compute' or 'If x=', do exact arithmetic (substitute x then evaluate).\",\n",
    "]\n",
    "LR_FACT = \"- LR_FACTS: y = beta0 + beta1 x; residual = y - y_hat; OLS minimizes SSE; R^2 explained variance share.\"\n",
    "\n",
    "def _append_once(note: str, line: str) -> str:\n",
    "    existing = set(ln.strip() for ln in note.splitlines() if ln.strip())\n",
    "    if line.strip() not in existing:\n",
    "        note = (note + \"\\n\" if note.strip() else \"\") + line\n",
    "    return note\n",
    "\n",
    "def f_theta_update(z_prev: str, text: str, config: Dict) -> str:\n",
    "    t = text.lower()\n",
    "    z = z_prev\n",
    "    for rule in META_RULES:\n",
    "        z = _append_once(z, rule)\n",
    "    if any(k in t for k in [\"linear regression\", \"ols\", \"residual\", \"r-squared\", \"ordinary least squares\"]):\n",
    "        z = _append_once(z, LR_FACT)\n",
    "    if len(z) > config[\"max_note_chars\"]:\n",
    "        z = z[-config[\"max_note_chars\"]:]\n",
    "    return z.strip()\n",
    "\n",
    "def g_theta_critique(z: str) -> str:\n",
    "    issues = []\n",
    "    for must in [\"guardrail\", \"heuristic\", \"meta_qa\", \"meta_sentiment\", \"meta_math\"]:\n",
    "        if must not in z.lower():\n",
    "            issues.append(f\"Missing {must}.\")\n",
    "    if len(z) > 1100:\n",
    "        issues.append(\"Too long; compress redundancy.\")\n",
    "    return \"\\n\".join(f\"- {i}\" for i in (issues or [\"OK.\"]))\n",
    "\n",
    "def r_theta_revise(z: str, critique: str, config: Dict) -> str:\n",
    "    lines, seen = [], set()\n",
    "    for line in z.splitlines():\n",
    "        key = line.strip().lower()\n",
    "        if key and key not in seen:\n",
    "            lines.append(line.strip())\n",
    "            seen.add(key)\n",
    "    z2 = \"\\n\".join(lines).strip()\n",
    "    if config[\"aggressive_compress\"] and len(z2) > config[\"revise_max_chars\"]:\n",
    "        keep = [ln for ln in z2.splitlines() if any(k in ln.lower() for k in [\"heuristic\", \"guardrail\", \"meta_\", \"lr_facts\"])]\n",
    "        z2 = \"\\n\".join(keep)[:config[\"revise_max_chars\"]].strip()\n",
    "    return z2\n",
    "\n",
    "def build_note_for_domain(domain: str, domain_text: str, questions: List[Dict[str, str]], config: Dict) -> Tuple[str, str]:\n",
    "    z = \"\"\n",
    "    z = f_theta_update(z, domain_text, config)\n",
    "    for qa in questions:\n",
    "        z = f_theta_update(z, qa[\"question\"], config)\n",
    "    note_raw = z\n",
    "    if config[\"revision\"]:\n",
    "        c = g_theta_critique(z)\n",
    "        z = r_theta_revise(z, c, config)\n",
    "    return note_raw, z\n",
    "\n",
    "def student_note_answer(question: str, note: str, domain_text_for_rag: str) -> str:\n",
    "    nl = note.lower()\n",
    "    ql = question.lower().strip()\n",
    "    has_guardrail = \"guardrail\" in nl\n",
    "\n",
    "    if ql.startswith(\"q:\"):\n",
    "        if \"meta_qa\" not in nl:\n",
    "            return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "        return solve_qa_from_context(question, domain_text_for_rag)\n",
    "\n",
    "    if \"sentiment of:\" in ql:\n",
    "        if \"meta_sentiment\" not in nl:\n",
    "            return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "        return solve_sentiment(question) or \"I don't know\"\n",
    "\n",
    "    if \"compute\" in ql:\n",
    "        if \"meta_math\" not in nl:\n",
    "            return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "        return solve_math(question) or \"I don't know\"\n",
    "\n",
    "    if any(k in ql for k in [\"linear regression\", \"ols\", \"residual\", \"r-squared\", \"ordinary least squares\"]):\n",
    "        if \"lr_facts\" not in nl:\n",
    "            return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "        return solve_lr(question) or \"I don't know\"\n",
    "\n",
    "    return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "\n",
    "\n",
    "\n",
    "# 7) Metrics\n",
    "\n",
    "def score_answer(pred: str, gold: str) -> float:\n",
    "    return float(norm(pred) == norm(gold))\n",
    "\n",
    "def abstain(pred: str) -> float:\n",
    "    return float(norm(pred) == \"i don't know\")\n",
    "\n",
    "def hallucination(pred: str, gold: str) -> float:\n",
    "    if abstain(pred) == 1.0:\n",
    "        return 0.0\n",
    "    return float(score_answer(pred, gold) == 0.0)\n",
    "\n",
    "def consistency_metric(question: str, answer_fn, *args) -> float:\n",
    "    a1 = answer_fn(question, *args)\n",
    "    a2 = answer_fn(paraphrase(question), *args)\n",
    "    return cosine_sim_text(a1, a2)\n",
    "\n",
    "def note_self_consistency(note: str) -> float:\n",
    "    lines = [ln.strip() for ln in note.splitlines() if ln.strip()]\n",
    "    if len(lines) < 4:\n",
    "        return 0.0\n",
    "    mid = len(lines)//2\n",
    "    return cosine_sim_text(\" \".join(lines[:mid]), \" \".join(lines[mid:]))\n",
    "\n",
    "def rel_note_len(note_final: str, domain_text: str) -> float:\n",
    "    return float(len(note_final) / max(1, len(domain_text)))\n",
    "\n",
    "def comp_gain(note_final: str, domain_text: str) -> float:\n",
    "    return float(len(domain_text) / max(1, len(note_final)))\n",
    "\n",
    "def note_answerability(note_final: str, questions: List[Dict[str, str]], domain_text: str) -> float:\n",
    "    return float(np.mean([1.0 - abstain(student_note_answer(q[\"question\"], note_final, domain_text)) for q in questions]))\n",
    "\n",
    "def LearningScore(acc: float, cons: float, halluc_rate: float) -> float:\n",
    "    return float(acc + cons - halluc_rate)\n",
    "\n",
    "def LearningScore_norm(acc: float, cons: float, halluc_rate: float) -> float:\n",
    "    return float((acc + cons - halluc_rate + 1.0) / 3.0)\n",
    "\n",
    "\n",
    "# 8) Runner + Logging\n",
    "\n",
    "@dataclass\n",
    "class RunSummary:\n",
    "    seed: int\n",
    "    domain: str\n",
    "    mode: str\n",
    "    acc: float\n",
    "    abstain_rate: float\n",
    "    halluc_rate: float\n",
    "    cons: float\n",
    "    learn: float\n",
    "    learnN: float\n",
    "    note_len_raw: int\n",
    "    note_len_final: int\n",
    "    note_selfc: float\n",
    "    rel_note_len: float\n",
    "    comp_gain: float\n",
    "    note_ansb: float\n",
    "\n",
    "def run_phase3():\n",
    "    ensure_dirs()\n",
    "    summaries = []\n",
    "    all_pred_rows = []\n",
    "\n",
    "    for domain in DOMAINS:\n",
    "        questions = load_questions(domain)\n",
    "        domain_text = load_domain_text(domain)\n",
    "        corpus = [q[\"question\"] for q in questions] + [q[\"expected\"] for q in questions] + [domain_text]\n",
    "        embedder.fit(corpus)\n",
    "\n",
    "        for seed in SEEDS:\n",
    "            set_seed(seed)\n",
    "            note_raw, note_final = build_note_for_domain(domain, domain_text, questions, CONFIG)\n",
    "\n",
    "            save_json({\"domain\": domain, \"seed\": seed, \"note_raw\": note_raw, \"note_final\": note_final},\n",
    "                      f\"phase3/notes/{domain}_{seed}.json\")\n",
    "\n",
    "            for mode in MODES:\n",
    "                rows = []\n",
    "                for t, qa in enumerate(questions, start=1):\n",
    "                    q, gold = qa[\"question\"], qa[\"expected\"]\n",
    "\n",
    "                    if mode == \"direct\":\n",
    "                        pred = direct_answer(q)\n",
    "                        cons = consistency_metric(q, lambda qq: direct_answer(qq))\n",
    "                    elif mode == \"rag\":\n",
    "                        pred = rag_answer(q, domain_text)\n",
    "                        cons = consistency_metric(q, lambda qq, dt: rag_answer(qq, dt), domain_text)\n",
    "                    else:\n",
    "                        pred = student_note_answer(q, note_final, domain_text)\n",
    "                        cons = consistency_metric(q, lambda qq, n, dt: student_note_answer(qq, n, dt), note_final, domain_text)\n",
    "\n",
    "                    rows.append({\n",
    "                        \"seed\": seed, \"domain\": domain, \"mode\": mode, \"t\": t,\n",
    "                        \"question\": q, \"gold\": gold, \"pred\": pred,\n",
    "                        \"acc\": score_answer(pred, gold),\n",
    "                        \"abstain\": abstain(pred),\n",
    "                        \"halluc\": hallucination(pred, gold),\n",
    "                        \"consistency\": cons\n",
    "                    })\n",
    "\n",
    "                df = pd.DataFrame(rows)\n",
    "                df.to_csv(f\"phase3/results/{domain}_{seed}_{mode}_preds.csv\", index=False)\n",
    "                all_pred_rows.append(df)\n",
    "\n",
    "                acc = float(df[\"acc\"].mean())\n",
    "                abst_rate = float(df[\"abstain\"].mean())\n",
    "                hall_rate = float(df[\"halluc\"].mean())\n",
    "                cons_mean = float(df[\"consistency\"].mean())\n",
    "                learn = LearningScore(acc, cons_mean, hall_rate)\n",
    "                learnN = LearningScore_norm(acc, cons_mean, hall_rate)\n",
    "\n",
    "                if mode == \"student_note\":\n",
    "                    nraw = len(note_raw)\n",
    "                    nfin = len(note_final)\n",
    "                    selfc = note_self_consistency(note_final)\n",
    "                    rlen = rel_note_len(note_final, domain_text)\n",
    "                    cg = comp_gain(note_final, domain_text)\n",
    "                    ansb = note_answerability(note_final, questions, domain_text)\n",
    "                else:\n",
    "                    nraw = nfin = 0\n",
    "                    selfc = rlen = cg = ansb = 0.0\n",
    "\n",
    "                summaries.append(asdict(RunSummary(\n",
    "                    seed=seed, domain=domain, mode=mode,\n",
    "                    acc=acc, abstain_rate=abst_rate, halluc_rate=hall_rate,\n",
    "                    cons=cons_mean, learn=learn, learnN=learnN,\n",
    "                    note_len_raw=nraw, note_len_final=nfin,\n",
    "                    note_selfc=selfc, rel_note_len=rlen, comp_gain=cg, note_ansb=ansb\n",
    "                )))\n",
    "\n",
    "    runs_df = pd.DataFrame(summaries)\n",
    "    pred_df = pd.concat(all_pred_rows, ignore_index=True)\n",
    "\n",
    "    agg_df = runs_df.groupby([\"domain\", \"mode\"]).agg(\n",
    "        acc_mean=(\"acc\", \"mean\"),\n",
    "        acc_std=(\"acc\", \"std\"),\n",
    "        abst_mean=(\"abstain_rate\", \"mean\"),\n",
    "        hall_mean=(\"halluc_rate\", \"mean\"),\n",
    "        cons_mean=(\"cons\", \"mean\"),\n",
    "        learn_mean=(\"learn\", \"mean\"),\n",
    "        learnN_mean=(\"learnN\", \"mean\"),\n",
    "        note_len_raw_mean=(\"note_len_raw\", \"mean\"),\n",
    "        note_len_final_mean=(\"note_len_final\", \"mean\"),\n",
    "        note_selfc_mean=(\"note_selfc\", \"mean\"),\n",
    "        rel_note_len_mean=(\"rel_note_len\", \"mean\"),\n",
    "        comp_gain_mean=(\"comp_gain\", \"mean\"),\n",
    "        note_ansb_mean=(\"note_ansb\", \"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    runs_df.to_csv(\"phase3/metrics/phase3_runs.csv\", index=False)\n",
    "    agg_df.to_csv(\"phase3/metrics/phase3_agg.csv\", index=False)\n",
    "    pred_df.to_csv(\"phase3/metrics/phase3_all_predictions.csv\", index=False)\n",
    "\n",
    "    # Cross-domain\n",
    "    cross_specs = [(\"linear_regression\", \"math\"), (\"math\", \"qa\"), (\"sentiment\", \"qa\"), (\"qa\", \"sentiment\")]\n",
    "    cross_rows = []\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        set_seed(seed)\n",
    "        for A, B in cross_specs:\n",
    "            qA = load_questions(A); textA = load_domain_text(A)\n",
    "            qB = load_questions(B); textB = load_domain_text(B)\n",
    "\n",
    "            corpusB = [q[\"question\"] for q in qB] + [q[\"expected\"] for q in qB] + [textB]\n",
    "            embedder.fit(corpusB)\n",
    "\n",
    "            note_raw_A, note_final_A = build_note_for_domain(A, textA, qA, CONFIG)\n",
    "\n",
    "            preds = []\n",
    "            for qa in qB:\n",
    "                q, gold = qa[\"question\"], qa[\"expected\"]\n",
    "                pred = student_note_answer(q, note_final_A, textB)\n",
    "                preds.append({\n",
    "                    \"acc\": score_answer(pred, gold),\n",
    "                    \"abstain\": abstain(pred),\n",
    "                    \"halluc\": hallucination(pred, gold),\n",
    "                    \"cons\": consistency_metric(q, lambda qq, n, dt: student_note_answer(qq, n, dt), note_final_A, textB),\n",
    "                })\n",
    "\n",
    "            dfB = pd.DataFrame(preds)\n",
    "            accB = float(dfB[\"acc\"].mean())\n",
    "            abstB = float(dfB[\"abstain\"].mean())\n",
    "            hallB = float(dfB[\"halluc\"].mean())\n",
    "            consB = float(dfB[\"cons\"].mean())\n",
    "\n",
    "            cross_rows.append({\n",
    "                \"seed\": seed, \"train_domain\": A, \"eval_domain\": B,\n",
    "                \"acc_B\": accB, \"abstain_B\": abstB, \"halluc_B\": hallB, \"cons_B\": consB,\n",
    "                \"LearningScore_B\": LearningScore(accB, consB, hallB),\n",
    "                \"LearningScore_B_norm\": LearningScore_norm(accB, consB, hallB),\n",
    "                \"note_len_raw\": len(note_raw_A),\n",
    "                \"note_len_final\": len(note_final_A),\n",
    "            })\n",
    "\n",
    "    cross_df = pd.DataFrame(cross_rows)\n",
    "    cross_df.to_csv(\"phase3/metrics/phase3_cross_domain.csv\", index=False)\n",
    "\n",
    "    print(\"PHASE 3 — AGG (head):\")\n",
    "    print(agg_df.head(12).to_string(index=False))\n",
    "    print(\"\\nPHASE 3 — CROSS-DOMAIN (head):\")\n",
    "    print(cross_df.head(12).to_string(index=False))\n",
    "    print(\"\\nSaved under: phase3/notes, phase3/results, phase3/metrics\")\n",
    "\n",
    "    return runs_df, agg_df, cross_df\n",
    "\n",
    "\n",
    "\n",
    "# 9) Run\n",
    "\n",
    "runs_df, agg_df, cross_df = run_phase3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bd6e7-0612-44a0-ac94-5136670e4f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2387cf-4ce7-48b4-a009-ec085e28068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PHASE 3—\n",
    "import os, re, json, random\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# 0) Reproducibility + utils\n",
    "\n",
    "SEEDS = [42, 123, 2025]\n",
    "DOMAINS = [\"linear_regression\", \"sentiment\", \"qa\", \"math\"]\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
    "\n",
    "def ensure_dirs():\n",
    "    os.makedirs(\"phase4\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/notes\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/results\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/metrics\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/failures\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/viz\", exist_ok=True)\n",
    "\n",
    "def save_json(obj, path: str):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "\n",
    "# 1) Datasets (same as Phase-3 toy protocol)\n",
    "\n",
    "def load_questions(domain: str) -> List[Dict[str, str]]:\n",
    "    if domain == \"linear_regression\":\n",
    "        return [\n",
    "            {\"question\": \"What does linear regression model?\", \"expected\": \"relationship between dependent and independent variables\"},\n",
    "            {\"question\": \"What is the goal of ordinary least squares?\", \"expected\": \"minimize sum of squared residuals\"},\n",
    "            {\"question\": \"Write the simple linear regression equation.\", \"expected\": \"y = beta0 + beta1 x\"},\n",
    "            {\"question\": \"What is a residual?\", \"expected\": \"difference between observed and predicted value\"},\n",
    "            {\"question\": \"What does a high R-squared indicate?\", \"expected\": \"model explains large fraction of variance\"},\n",
    "        ]\n",
    "    if domain == \"sentiment\":\n",
    "        return [\n",
    "            {\"question\": \"Sentiment of: 'I loved this movie, it was fantastic.'\", \"expected\": \"positive\"},\n",
    "            {\"question\": \"Sentiment of: 'This was awful and boring.'\", \"expected\": \"negative\"},\n",
    "            {\"question\": \"Sentiment of: 'Not bad, but not great either.'\", \"expected\": \"neutral\"},\n",
    "            {\"question\": \"Sentiment of: 'Absolutely terrible experience.'\", \"expected\": \"negative\"},\n",
    "            {\"question\": \"Sentiment of: 'I really enjoyed it.'\", \"expected\": \"positive\"},\n",
    "        ]\n",
    "    if domain == \"qa\":\n",
    "        return [\n",
    "            {\"question\": \"Q: What is the capital of France?\", \"expected\": \"paris\"},\n",
    "            {\"question\": \"Q: At what temperature does water freeze?\", \"expected\": \"0°C\"},\n",
    "            {\"question\": \"Q: What does the Earth orbit?\", \"expected\": \"the sun\"},\n",
    "            {\"question\": \"Q: Where is the Nile?\", \"expected\": \"africa\"},\n",
    "            {\"question\": \"Q: What is Python?\", \"expected\": \"a programming language\"},\n",
    "        ]\n",
    "    if domain == \"math\":\n",
    "        return [\n",
    "            {\"question\": \"Compute 7 + 5.\", \"expected\": \"12\"},\n",
    "            {\"question\": \"Compute 9 * 3.\", \"expected\": \"27\"},\n",
    "            {\"question\": \"If x=4, compute 2x+1.\", \"expected\": \"9\"},\n",
    "            {\"question\": \"Compute 15 - 8.\", \"expected\": \"7\"},\n",
    "            {\"question\": \"Compute 24 / 6.\", \"expected\": \"4\"},\n",
    "        ]\n",
    "    raise ValueError(domain)\n",
    "\n",
    "def load_domain_text(domain: str) -> str:\n",
    "    if domain == \"linear_regression\":\n",
    "        return (\n",
    "            \"Linear Regression models the relationship between a dependent variable y and an independent variable x. \"\n",
    "            \"In simple linear regression: y = beta0 + beta1 x. \"\n",
    "            \"Ordinary Least Squares (OLS) estimates parameters by minimizing the sum of squared residuals, where residual = y - y_hat. \"\n",
    "            \"R-squared measures the fraction of variance explained by the model.\"\n",
    "        )\n",
    "    if domain == \"sentiment\":\n",
    "        return (\n",
    "            \"Sentiment analysis classifies text as positive, negative, or neutral. \"\n",
    "            \"Positive cues include words like loved, fantastic, enjoyed. \"\n",
    "            \"Negative cues include awful, terrible, boring. \"\n",
    "            \"Mixed or hedged statements often indicate neutrality.\"\n",
    "        )\n",
    "    if domain == \"qa\":\n",
    "        return (\n",
    "            \"Paris is the capital of France. \"\n",
    "            \"Water freezes at 0°C. \"\n",
    "            \"The Earth orbits the Sun. \"\n",
    "            \"The Nile is a river in Africa. \"\n",
    "            \"Python is a programming language.\"\n",
    "        )\n",
    "    if domain == \"math\":\n",
    "        return (\n",
    "            \"Arithmetic requires exact computation. \"\n",
    "            \"For 'If x=4, compute 2x+1', substitute x then evaluate carefully. \"\n",
    "            \"Use sanity checks for basic operations.\"\n",
    "        )\n",
    "    raise ValueError(domain)\n",
    "\n",
    "\n",
    "\n",
    "# 2) Embedder (for consistency)\n",
    "class Embedder:\n",
    "    def __init__(self):\n",
    "        self.vec = TfidfVectorizer()\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, texts: List[str]):\n",
    "        self.vec.fit(texts)\n",
    "        self.fitted = True\n",
    "\n",
    "    def encode(self, texts: List[str]):\n",
    "        if not self.fitted:\n",
    "            self.fit(texts)\n",
    "        return self.vec.transform(texts)\n",
    "\n",
    "embedder = Embedder()\n",
    "\n",
    "def cosine_sim_text(a: str, b: str) -> float:\n",
    "    V = embedder.encode([a, b])\n",
    "    return float(cosine_similarity(V[0], V[1])[0, 0])\n",
    "\n",
    "def paraphrase(question: str) -> str:\n",
    "    q = question.strip()\n",
    "    ql = q.lower()\n",
    "    if ql.startswith(\"q:\"):\n",
    "        return \"Q: (rephrased) \" + q[2:].strip()\n",
    "    if \"sentiment of:\" in ql:\n",
    "        return q.replace(\"Sentiment of:\", \"Sentiment of: (rephrased)\")\n",
    "    if \"compute\" in ql:\n",
    "        return q + \" (rephrased)\"\n",
    "    return \"Paraphrase: \" + q\n",
    "\n",
    "\n",
    "# 3) Deterministic solvers (offline “LLM-like”)\n",
    "# \n",
    "def safe_eval_arith(expr: str) -> Optional[float]:\n",
    "    expr = expr.strip()\n",
    "    if not expr:\n",
    "        return None\n",
    "    if re.search(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", expr):\n",
    "        return None\n",
    "    if not re.search(r\"\\d\", expr):\n",
    "        return None\n",
    "    try:\n",
    "        return eval(expr, {\"__builtins__\": {}}, {})\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def solve_math(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if \"compute\" not in ql:\n",
    "        return None\n",
    "\n",
    "    if \"if x=\" in ql:\n",
    "        mx = re.search(r\"if x\\s*=\\s*(\\d+)\", ql)\n",
    "        if not mx:\n",
    "            return \"I don't know\"\n",
    "        xval = int(mx.group(1))\n",
    "        mform = re.search(r\"compute\\s*(.*?)(?:\\.\\s*|$)\", ql)\n",
    "        if not mform:\n",
    "            return \"I don't know\"\n",
    "        formula = mform.group(1).strip().replace(\"x\", str(xval))\n",
    "        formula = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", \"\", formula)\n",
    "        val = safe_eval_arith(formula)\n",
    "        if val is None:\n",
    "            return \"I don't know\"\n",
    "        if abs(val - round(val)) < 1e-9:\n",
    "            val = int(round(val))\n",
    "        return str(val)\n",
    "\n",
    "    m = re.search(r\"compute\\s*(.*?)(?:\\.\\s*|$)\", ql)\n",
    "    if not m:\n",
    "        return \"I don't know\"\n",
    "    expr = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", \"\", m.group(1).strip())\n",
    "    val = safe_eval_arith(expr)\n",
    "    if val is None:\n",
    "        return \"I don't know\"\n",
    "    if abs(val - round(val)) < 1e-9:\n",
    "        val = int(round(val))\n",
    "    return str(val)\n",
    "\n",
    "def solve_sentiment(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if \"sentiment of:\" not in ql:\n",
    "        return None\n",
    "    if any(w in ql for w in [\"loved\", \"fantastic\", \"enjoyed\"]):\n",
    "        return \"positive\"\n",
    "    if any(w in ql for w in [\"awful\", \"terrible\", \"boring\"]):\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n",
    "\n",
    "def solve_lr(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if not any(k in ql for k in [\"linear regression\", \"ordinary least squares\", \"ols\", \"residual\", \"r-squared\"]):\n",
    "        return None\n",
    "    if \"model\" in ql: return \"relationship between dependent and independent variables\"\n",
    "    if \"ordinary least squares\" in ql or \"ols\" in ql: return \"minimize sum of squared residuals\"\n",
    "    if \"equation\" in ql: return \"y = beta0 + beta1 x\"\n",
    "    if \"residual\" in ql: return \"difference between observed and predicted value\"\n",
    "    if \"r-squared\" in ql: return \"model explains large fraction of variance\"\n",
    "    return \"I don't know\"\n",
    "\n",
    "def solve_qa_from_context(q: str, ctx: str) -> str:\n",
    "    ql = q.lower()\n",
    "    cl = ctx.lower()\n",
    "    if \"capital of france\" in ql and \"paris\" in cl: return \"paris\"\n",
    "    if \"temperature\" in ql and (\"0°\" in ctx or \"0\" in ctx): return \"0°C\"\n",
    "    if \"earth orbit\" in ql and \"sun\" in cl: return \"the sun\"\n",
    "    if \"where is the nile\" in ql and \"africa\" in cl: return \"africa\"\n",
    "    if \"what is python\" in ql and \"programming language\" in cl: return \"a programming language\"\n",
    "    return \"I don't know\"\n",
    "\n",
    "\n",
    "# \n",
    "# 4) Ablation modes\n",
    "# \n",
    "ABLATION_MODES = {\n",
    "    \"full\":        {\"child\": True,  \"steps\": True,  \"mistake\": True,  \"revision\": True,  \"memory\": True},\n",
    "    \"no_child\":    {\"child\": False, \"steps\": True,  \"mistake\": True,  \"revision\": True,  \"memory\": True},\n",
    "    \"no_steps\":    {\"child\": True,  \"steps\": False, \"mistake\": True,  \"revision\": True,  \"memory\": True},\n",
    "    \"no_mistake\":  {\"child\": True,  \"steps\": True,  \"mistake\": False, \"revision\": True,  \"memory\": True},\n",
    "    \"no_revision\": {\"child\": True,  \"steps\": True,  \"mistake\": True,  \"revision\": False, \"memory\": True},\n",
    "    \"no_memory\":   {\"child\": True,  \"steps\": True,  \"mistake\": True,  \"revision\": True,  \"memory\": False},\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    \"max_note_chars\": 2500,\n",
    "    \"revise_max_chars\": 650,\n",
    "    \"aggressive_compress\": True,\n",
    "}\n",
    "\n",
    "# Dynamic note template (Phase-4 requirement)\n",
    "def build_template(cfg: Dict) -> str:\n",
    "    parts = [\"1. One-sentence idea\"]\n",
    "    if cfg[\"child\"]:\n",
    "        parts.append(\"2. Simple explanation for a child\")\n",
    "    if cfg[\"steps\"]:\n",
    "        parts.append(\"3. Step-by-step procedure\")\n",
    "    if cfg[\"mistake\"]:\n",
    "        parts.append(\"4. Common mistake\")\n",
    "    parts.append(\"5. One question I still have\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "# \n",
    "# 5) Note generation (ablation-aware, offline)\n",
    "# We implement components as rule-blocks in the note.\n",
    "# Removing a component removes the corresponding block, which can measurably affect answer gating.\n",
    "# \n",
    "def _append_once(note: str, line: str) -> str:\n",
    "    existing = set(ln.strip() for ln in note.splitlines() if ln.strip())\n",
    "    if line.strip() not in existing:\n",
    "        note = (note + \"\\n\" if note.strip() else \"\") + line\n",
    "    return note\n",
    "\n",
    "def generate_note(domain_text: str, cfg: Dict, domain_hint: str) -> str:\n",
    "    \"\"\"\n",
    "    Offline note builder that mirrors 'template' sections.\n",
    "    This is where ablation actually removes content.\n",
    "    \"\"\"\n",
    "    note = \"\"\n",
    "    template = build_template(cfg)\n",
    "\n",
    "    # Core always-on (one-sentence idea)\n",
    "    note = _append_once(note, f\"- TEMPLATE:\\n{template}\")\n",
    "\n",
    "    # Components -> add content blocks\n",
    "    if cfg[\"child\"]:\n",
    "        note = _append_once(note, \"- CHILD: explain simply; define key terms in plain language.\")\n",
    "\n",
    "    if cfg[\"steps\"]:\n",
    "        note = _append_once(note, \"- STEPS: identify task type; retrieve evidence; compute/extract; verify; answer.\")\n",
    "\n",
    "    if cfg[\"mistake\"]:\n",
    "        note = _append_once(note, \"- MISTAKE: common error is answering without evidence/context; use guardrail.\")\n",
    "\n",
    "    # Domain-agnostic meta skills (treated as part of steps/mistake)\n",
    "    if cfg[\"steps\"]:\n",
    "        note = _append_once(note, \"- META_QA: If question starts with 'Q:', retrieve context from corpus and answer using only context.\")\n",
    "        note = _append_once(note, \"- META_SENTIMENT: If question contains 'Sentiment of:', use polarity cues to classify.\")\n",
    "        note = _append_once(note, \"- META_MATH: If question contains 'Compute' or 'If x=', do exact arithmetic carefully.\")\n",
    "\n",
    "    if cfg[\"mistake\"]:\n",
    "        note = _append_once(note, \"- GUARDRAIL: if evidence missing, abstain with 'I don't know'.\")\n",
    "\n",
    "    # Optional domain facts (helps LR when available)\n",
    "    if domain_hint == \"linear_regression\":\n",
    "        note = _append_once(note, \"- LR_FACTS: y = beta0 + beta1 x; residual = y - y_hat; OLS minimizes SSE; R^2 explained variance share.\")\n",
    "\n",
    "    # Bound\n",
    "    if len(note) > CONFIG[\"max_note_chars\"]:\n",
    "        note = note[-CONFIG[\"max_note_chars\"]:]\n",
    "    return note.strip()\n",
    "\n",
    "def critique(note: str) -> str:\n",
    "    issues = []\n",
    "    nl = note.lower()\n",
    "    if \"guardrail\" not in nl:\n",
    "        issues.append(\"Missing guardrail.\")\n",
    "    if \"meta_qa\" not in nl or \"meta_math\" not in nl or \"meta_sentiment\" not in nl:\n",
    "        issues.append(\"Missing some meta rules; may harm cross-domain.\")\n",
    "    if len(note) > 1100:\n",
    "        issues.append(\"Too long; compress redundancy.\")\n",
    "    return \"\\n\".join(f\"- {i}\" for i in (issues or [\"OK.\"]))\n",
    "\n",
    "def revise(note: str, critique_text: str, cfg: Dict) -> str:\n",
    "    # de-dup\n",
    "    lines, seen = [], set()\n",
    "    for line in note.splitlines():\n",
    "        key = line.strip().lower()\n",
    "        if key and key not in seen:\n",
    "            lines.append(line.strip())\n",
    "            seen.add(key)\n",
    "    out = \"\\n\".join(lines).strip()\n",
    "\n",
    "    if cfg[\"revision\"] and CONFIG[\"aggressive_compress\"] and len(out) > CONFIG[\"revise_max_chars\"]:\n",
    "        keep = [ln for ln in out.splitlines() if any(k in ln.lower() for k in [\"template\", \"child\", \"steps\", \"mistake\", \"meta_\", \"guardrail\", \"lr_facts\"])]\n",
    "        out = \"\\n\".join(keep)[:CONFIG[\"revise_max_chars\"]].strip()\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# \n",
    "# 6) Memory store (external state)\n",
    "# For Phase-4, \"no_memory\" means we do NOT store/retain note.\n",
    "# \n",
    "MEMORY_STORE: Dict[str, str] = {}\n",
    "\n",
    "def store_note(key: str, note: str):\n",
    "    MEMORY_STORE[key] = note\n",
    "\n",
    "def load_note(key: str) -> str:\n",
    "    return MEMORY_STORE.get(key, \"\")\n",
    "\n",
    "\n",
    "# \n",
    "# 7) Student-note answer (ablation-aware via missing blocks)\n",
    "#\n",
    "def student_note_answer(question: str, note: str, retrieval_corpus: str) -> str:\n",
    "    nl = note.lower()\n",
    "    ql = question.lower().strip()\n",
    "    has_guardrail = \"guardrail\" in nl\n",
    "\n",
    "    if ql.startswith(\"q:\"):\n",
    "        if \"meta_qa\" not in nl:\n",
    "            return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "        return solve_qa_from_context(question, retrieval_corpus)\n",
    "\n",
    "    if \"sentiment of:\" in ql:\n",
    "        if \"meta_sentiment\" not in nl:\n",
    "            return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "        return solve_sentiment(question) or \"I don't know\"\n",
    "\n",
    "    if \"compute\" in ql:\n",
    "        if \"meta_math\" not in nl:\n",
    "            return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "        return solve_math(question) or \"I don't know\"\n",
    "\n",
    "    if any(k in ql for k in [\"linear regression\", \"ols\", \"residual\", \"r-squared\", \"ordinary least squares\"]):\n",
    "        if \"lr_facts\" not in nl:\n",
    "            return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "        return solve_lr(question) or \"I don't know\"\n",
    "\n",
    "    return \"I don't know\" if has_guardrail else \"I don't know\"\n",
    "\n",
    "\n",
    "\n",
    "# 8) Metrics + Learning score\n",
    "\n",
    "def score_answer(pred: str, gold: str) -> float:\n",
    "    return float(norm(pred) == norm(gold))\n",
    "\n",
    "def abstain(pred: str) -> float:\n",
    "    return float(norm(pred) == \"i don't know\")\n",
    "\n",
    "def hallucination(pred: str, gold: str) -> float:\n",
    "    if abstain(pred) == 1.0:\n",
    "        return 0.0\n",
    "    return float(score_answer(pred, gold) == 0.0)\n",
    "\n",
    "def consistency_metric(question: str, answer_fn, *args) -> float:\n",
    "    a1 = answer_fn(question, *args)\n",
    "    a2 = answer_fn(paraphrase(question), *args)\n",
    "    return cosine_sim_text(a1, a2)\n",
    "\n",
    "def LearningScore(acc: float, cons: float, hall: float) -> float:\n",
    "    return float(acc + cons - hall)\n",
    "\n",
    "\n",
    "\n",
    "# 9) Failure tagging heuristics (automatic)\n",
    "\n",
    "def tag_failure(mode: str, cfg: Dict, note: str, q: str, pred: str, gold: str, domain_text: str) -> List[str]:\n",
    "    tags = []\n",
    "    nl = note.lower()\n",
    "    ql = q.lower()\n",
    "\n",
    "    # Abstention dominated\n",
    "    if norm(pred) == \"i don't know\":\n",
    "        tags.append(\"abstention\")\n",
    "        if cfg.get(\"mistake\") is False or \"guardrail\" not in nl:\n",
    "            tags.append(\"missing_guardrail_or_mistake\")\n",
    "        if \"meta_qa\" not in nl and ql.startswith(\"q:\"):\n",
    "            tags.append(\"missing_meta_qa\")\n",
    "        if \"meta_math\" not in nl and \"compute\" in ql:\n",
    "            tags.append(\"missing_meta_math\")\n",
    "        if \"meta_sentiment\" not in nl and \"sentiment of:\" in ql:\n",
    "            tags.append(\"missing_meta_sentiment\")\n",
    "\n",
    "    # Confident wrong\n",
    "    if norm(pred) != \"i don't know\" and norm(pred) != norm(gold):\n",
    "        tags.append(\"confident_wrong\")\n",
    "\n",
    "    # Over-compression / missing content\n",
    "    if len(note) < 180:\n",
    "        tags.append(\"over_compression\")\n",
    "\n",
    "    # Missing component signals\n",
    "    if cfg.get(\"child\") is False:\n",
    "        tags.append(\"no_child_component\")\n",
    "    if cfg.get(\"steps\") is False:\n",
    "        tags.append(\"no_steps_component\")\n",
    "    if cfg.get(\"mistake\") is False:\n",
    "        tags.append(\"no_mistake_component\")\n",
    "    if cfg.get(\"revision\") is False:\n",
    "        tags.append(\"no_revision_component\")\n",
    "    if cfg.get(\"memory\") is False:\n",
    "        tags.append(\"no_memory_component\")\n",
    "\n",
    "    # Retrieval context mismatch (QA without retrieval)\n",
    "    if ql.startswith(\"q:\") and \"paris\" in domain_text.lower() and norm(pred) == \"i don't know\":\n",
    "        tags.append(\"retrieval_not_used\")\n",
    "\n",
    "    return sorted(set(tags))\n",
    "\n",
    "\n",
    "\n",
    "# 10) Run ablation experiment\n",
    "# Outputs:\n",
    "# - phase4/metrics/ablation_runs.csv\n",
    "# - phase4/metrics/ablation_agg.csv\n",
    "# - phase4/metrics/ablation_drop.csv\n",
    "# - phase4/failures/failures.json\n",
    "# - phase4/failures/failures_tagged.json\n",
    "# - phase4/viz/ablation_drop_bar.png\n",
    "\n",
    "def run_phase4():\n",
    "    ensure_dirs()\n",
    "    MEMORY_STORE.clear()\n",
    "\n",
    "    run_rows = []\n",
    "    pred_rows = []\n",
    "    failures = []\n",
    "\n",
    "    for domain in DOMAINS:\n",
    "        questions = load_questions(domain)\n",
    "        domain_text = load_domain_text(domain)\n",
    "\n",
    "        # embedder fit per domain for stable cosine similarities\n",
    "        corpus = [q[\"question\"] for q in questions] + [q[\"expected\"] for q in questions] + [domain_text]\n",
    "        embedder.fit(corpus)\n",
    "\n",
    "        for seed in SEEDS:\n",
    "            set_seed(seed)\n",
    "\n",
    "            for mode_name, cfg in ABLATION_MODES.items():\n",
    "                # Build note\n",
    "                note = generate_note(domain_text, cfg, domain_hint=domain)\n",
    "\n",
    "                # Revision if enabled\n",
    "                if cfg[\"revision\"]:\n",
    "                    crit = critique(note)\n",
    "                    note = revise(note, crit, cfg)\n",
    "\n",
    "                # Memory behavior\n",
    "                mem_key = f\"{domain}_{seed}_{mode_name}\"\n",
    "                if cfg[\"memory\"]:\n",
    "                    store_note(mem_key, note)\n",
    "                    note_for_answer = load_note(mem_key)\n",
    "                else:\n",
    "                    # no memory => do not store; also do not load\n",
    "                    note_for_answer = note  # still can answer within-run, but not retained externally\n",
    "\n",
    "                # Save note artifact per run\n",
    "                save_json(\n",
    "                    {\"domain\": domain, \"seed\": seed, \"ablation_mode\": mode_name, \"config\": cfg, \"note\": note_for_answer},\n",
    "                    f\"phase4/notes/{domain}_{seed}_{mode_name}.json\"\n",
    "                )\n",
    "\n",
    "                # Evaluate questions\n",
    "                per_q = []\n",
    "                for t, qa in enumerate(questions, start=1):\n",
    "                    q, gold = qa[\"question\"], qa[\"expected\"]\n",
    "                    pred = student_note_answer(q, note_for_answer, domain_text)\n",
    "\n",
    "                    acc = score_answer(pred, gold)\n",
    "                    abst = abstain(pred)\n",
    "                    hall = hallucination(pred, gold)\n",
    "                    cons = consistency_metric(q, lambda qq, n, dt: student_note_answer(qq, n, dt), note_for_answer, domain_text)\n",
    "\n",
    "                    ls = LearningScore(acc, cons, hall)\n",
    "\n",
    "                    row = {\n",
    "                        \"seed\": seed,\n",
    "                        \"domain\": domain,\n",
    "                        \"ablation_mode\": mode_name,\n",
    "                        \"t\": t,\n",
    "                        \"question\": q,\n",
    "                        \"gold\": gold,\n",
    "                        \"pred\": pred,\n",
    "                        \"acc\": acc,\n",
    "                        \"abstain\": abst,\n",
    "                        \"halluc\": hall,\n",
    "                        \"cons\": cons,\n",
    "                        \"LearningScore\": ls,\n",
    "                        \"note_len\": len(note_for_answer),\n",
    "                    }\n",
    "                    pred_rows.append(row)\n",
    "                    per_q.append(row)\n",
    "\n",
    "                    # Failure capture rule: acc==0 AND (confident wrong OR abstain) => always a failure case\n",
    "                    if acc < 0.5:\n",
    "                        failures.append({\n",
    "                            \"seed\": seed,\n",
    "                            \"domain\": domain,\n",
    "                            \"ablation_mode\": mode_name,\n",
    "                            \"config\": cfg,\n",
    "                            \"note\": note_for_answer,\n",
    "                            \"question\": q,\n",
    "                            \"gold\": gold,\n",
    "                            \"pred\": pred,\n",
    "                            \"acc\": acc,\n",
    "                        })\n",
    "\n",
    "                df = pd.DataFrame(per_q)\n",
    "                run_rows.append({\n",
    "                    \"seed\": seed,\n",
    "                    \"domain\": domain,\n",
    "                    \"ablation_mode\": mode_name,\n",
    "                    \"acc_mean\": float(df[\"acc\"].mean()),\n",
    "                    \"abst_mean\": float(df[\"abstain\"].mean()),\n",
    "                    \"hall_mean\": float(df[\"halluc\"].mean()),\n",
    "                    \"cons_mean\": float(df[\"cons\"].mean()),\n",
    "                    \"learn_mean\": float(df[\"LearningScore\"].mean()),\n",
    "                    \"note_len_mean\": float(df[\"note_len\"].mean()),\n",
    "                })\n",
    "\n",
    "                df.to_csv(f\"phase4/results/{domain}_{seed}_{mode_name}_preds.csv\", index=False)\n",
    "\n",
    "    runs_df = pd.DataFrame(run_rows)\n",
    "    preds_df = pd.DataFrame(pred_rows)\n",
    "\n",
    "    # Aggregate across seeds (mean±std)\n",
    "    agg_df = runs_df.groupby([\"domain\", \"ablation_mode\"]).agg(\n",
    "        acc_mean=(\"acc_mean\", \"mean\"),\n",
    "        acc_std=(\"acc_mean\", \"std\"),\n",
    "        abst_mean=(\"abst_mean\", \"mean\"),\n",
    "        hall_mean=(\"hall_mean\", \"mean\"),\n",
    "        cons_mean=(\"cons_mean\", \"mean\"),\n",
    "        learn_mean=(\"learn_mean\", \"mean\"),\n",
    "        note_len_mean=(\"note_len_mean\", \"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute drop vs full (per domain)\n",
    "    full = agg_df[agg_df[\"ablation_mode\"] == \"full\"][[\"domain\", \"learn_mean\"]].rename(columns={\"learn_mean\": \"learn_full\"})\n",
    "    drop_df = agg_df.merge(full, on=\"domain\", how=\"left\")\n",
    "    drop_df[\"learn_drop_vs_full\"] = drop_df[\"learn_full\"] - drop_df[\"learn_mean\"]\n",
    "\n",
    "    # Failure tagging\n",
    "    failures_tagged = []\n",
    "    for f in failures:\n",
    "        tags = tag_failure(\n",
    "            mode=f[\"ablation_mode\"],\n",
    "            cfg=f[\"config\"],\n",
    "            note=f[\"note\"],\n",
    "            q=f[\"question\"],\n",
    "            pred=f[\"pred\"],\n",
    "            gold=f[\"gold\"],\n",
    "            domain_text=load_domain_text(f[\"domain\"])\n",
    "        )\n",
    "        ft = dict(f)\n",
    "        ft[\"tags\"] = tags\n",
    "        failures_tagged.append(ft)\n",
    "\n",
    "    # Save artifacts\n",
    "    runs_df.to_csv(\"phase4/metrics/ablation_runs.csv\", index=False)\n",
    "    agg_df.to_csv(\"phase4/metrics/ablation_agg.csv\", index=False)\n",
    "    drop_df.to_csv(\"phase4/metrics/ablation_drop.csv\", index=False)\n",
    "    preds_df.to_csv(\"phase4/metrics/ablation_all_predictions.csv\", index=False)\n",
    "\n",
    "    save_json(failures, \"phase4/failures/failures.json\")\n",
    "    save_json(failures_tagged, \"phase4/failures/failures_tagged.json\")\n",
    "\n",
    "    # Visualization: average drop across domains per ablation mode\n",
    "    drop_summary = drop_df.groupby(\"ablation_mode\")[\"learn_drop_vs_full\"].mean().sort_values(ascending=False).reset_index()\n",
    "    plt.figure()\n",
    "    plt.bar(drop_summary[\"ablation_mode\"], drop_summary[\"learn_drop_vs_full\"])\n",
    "    plt.ylabel(\"Mean LearningScore drop vs full\")\n",
    "    plt.title(\"Ablation Component Importance (mean drop across domains)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"phase4/viz/ablation_drop_bar.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"PHASE 4 — ABLATION AGG (head):\")\n",
    "    print(agg_df.head(12).to_string(index=False))\n",
    "    print(\"\\nPHASE 4 — DROP vs FULL (head):\")\n",
    "    print(drop_df.sort_values(['domain','learn_drop_vs_full'], ascending=[True, False]).head(12).to_string(index=False))\n",
    "    print(\"\\nSaved under: phase4/ (notes/, results/, metrics/, failures/, viz/)\")\n",
    "    print(\"Key files:\")\n",
    "    print(\" - phase4/metrics/ablation_agg.csv\")\n",
    "    print(\" - phase4/metrics/ablation_drop.csv\")\n",
    "    print(\" - phase4/failures/failures_tagged.json\")\n",
    "    print(\" - phase4/viz/ablation_drop_bar.png\")\n",
    "\n",
    "    return runs_df, agg_df, drop_df, failures_tagged\n",
    "\n",
    "\n",
    "# 11) Run Phase-3\n",
    "\n",
    "runs_df, agg_df, drop_df, failures_tagged = run_phase4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2668c7-e690-49c7-bf72-de0cc9f33712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PHASE 4 — Ablation & Failure Case Analysis \n",
    "# Includes the requested fix:\n",
    "# - Explicit [GUARDRAIL_ON]/[GUARDRAIL_OFF] tags (robust)\n",
    "# - QA domain included\n",
    "# - QA has context-missing questions (gold = \"I don't know\")\n",
    "# - no_mistake => forced hallucination on missing-context QA (Berlin/Red/etc.)\n",
    "# - FULL remains best reference; drops are non-negative and interpretable\n",
    "#\n",
    "# Outputs:\n",
    "# - phase4/metrics/ablation_runs.csv\n",
    "# - phase4/metrics/ablation_agg.csv\n",
    "# - phase4/metrics/ablation_drop.csv\n",
    "# - phase4/failures/failures_tagged.json\n",
    "# - phase4/viz/ablation_drop_bar.png\n",
    "\n",
    "import os, re, json, random\n",
    "from typing import Dict, List, Optional\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "# 0) Reproducibility + IO\n",
    "\n",
    "SEEDS = [42, 123, 2025]\n",
    "DOMAINS = [\"linear_regression\", \"math\", \"qa\"]\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
    "\n",
    "def tokenize(s: str) -> List[str]:\n",
    "    return re.findall(r\"[a-z0-9°]+\", norm(s))\n",
    "\n",
    "def ensure_dirs():\n",
    "    os.makedirs(\"phase4\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/notes\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/results\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/metrics\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/failures\", exist_ok=True)\n",
    "    os.makedirs(\"phase4/viz\", exist_ok=True)\n",
    "\n",
    "def save_json(obj, path: str):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "\n",
    "# 1) Datasets (QA includes context-missing questions)\n",
    "\n",
    "def load_questions(domain: str) -> List[Dict[str, str]]:\n",
    "    if domain == \"linear_regression\":\n",
    "        return [\n",
    "            {\"question\": \"Explain simply: what is linear regression?\", \"expected\": \"relationship between dependent and independent variables\"},\n",
    "            {\"question\": \"What does linear regression model?\", \"expected\": \"relationship between dependent and independent variables\"},\n",
    "            {\"question\": \"Write the simple linear regression equation.\", \"expected\": \"y = beta0 + beta1 x\"},\n",
    "            {\"question\": \"What is a residual?\", \"expected\": \"difference between observed and predicted value\"},\n",
    "            {\"question\": \"What is the goal of ordinary least squares?\", \"expected\": \"minimize sum of squared residuals\"},\n",
    "        ]\n",
    "    if domain == \"math\":\n",
    "        return [\n",
    "            {\"question\": \"Explain simply: what is addition?\", \"expected\": \"combining numbers to get a total\"},\n",
    "            {\"question\": \"Compute 7 + 5.\", \"expected\": \"12\"},\n",
    "            {\"question\": \"Compute 9 * 3.\", \"expected\": \"27\"},\n",
    "            {\"question\": \"If x=4, compute 2x+1.\", \"expected\": \"9\"},\n",
    "            {\"question\": \"Compute 15 - 8.\", \"expected\": \"7\"},\n",
    "        ]\n",
    "    if domain == \"qa\":\n",
    "        return [\n",
    "            {\"question\": \"Explain simply: what is a capital city?\", \"expected\": \"main city of a country\"},\n",
    "            {\"question\": \"Q: What is the capital of France?\", \"expected\": \"paris\"},\n",
    "            {\"question\": \"Q: At what temperature does water freeze?\", \"expected\": \"0°C\"},\n",
    "            # context-missing (gold is abstention)\n",
    "            {\"question\": \"Q: What is the capital of Germany?\", \"expected\": \"I don't know\"},\n",
    "            {\"question\": \"Q: What is the color of Mars?\", \"expected\": \"I don't know\"},\n",
    "        ]\n",
    "    raise ValueError(domain)\n",
    "\n",
    "def load_domain_text(domain: str) -> str:\n",
    "    if domain == \"linear_regression\":\n",
    "        return (\n",
    "            \"Linear Regression models the relationship between a dependent variable y and an independent variable x. \"\n",
    "            \"In simple linear regression: y = beta0 + beta1 x. \"\n",
    "            \"Ordinary Least Squares (OLS) estimates parameters by minimizing the sum of squared residuals, where residual = y - y_hat.\"\n",
    "        )\n",
    "    if domain == \"math\":\n",
    "        return \"Arithmetic requires exact computation. Addition means combining numbers to get a total.\"\n",
    "    if domain == \"qa\":\n",
    "        return (\n",
    "            \"Paris is the capital of France. Water freezes at 0°C. The Earth orbits the Sun. \"\n",
    "            \"The Nile is a river in Africa. A capital city is the main city of a country.\"\n",
    "        )\n",
    "    raise ValueError(domain)\n",
    "\n",
    "\n",
    "\n",
    "# 2) Embedder for consistency (TF-IDF)\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self):\n",
    "        self.vec = TfidfVectorizer()\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, texts: List[str]):\n",
    "        self.vec.fit(texts)\n",
    "        self.fitted = True\n",
    "\n",
    "    def encode(self, texts: List[str]):\n",
    "        if not self.fitted:\n",
    "            self.fit(texts)\n",
    "        return self.vec.transform(texts)\n",
    "\n",
    "embedder = Embedder()\n",
    "\n",
    "def cos_sim(a: str, b: str) -> float:\n",
    "    V = embedder.encode([a, b])\n",
    "    return float(cosine_similarity(V[0], V[1])[0, 0])\n",
    "\n",
    "def paraphrase(q: str) -> str:\n",
    "    q = q.strip()\n",
    "    ql = q.lower()\n",
    "    if ql.startswith(\"q:\"):\n",
    "        return \"Q: (rephrased) \" + q[2:].strip()\n",
    "    if \"compute\" in ql or \"if x=\" in ql:\n",
    "        return q + \" (rephrased)\"\n",
    "    if \"explain\" in ql:\n",
    "        return \"Explain (rephrased): \" + q\n",
    "    return \"Paraphrase: \" + q\n",
    "\n",
    "\n",
    "\n",
    "# 3) Deterministic solvers\n",
    "\n",
    "def safe_eval_arith(expr: str) -> Optional[float]:\n",
    "    expr = expr.strip()\n",
    "    if not expr:\n",
    "        return None\n",
    "    if re.search(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", expr):\n",
    "        return None\n",
    "    if not re.search(r\"\\d\", expr):\n",
    "        return None\n",
    "    try:\n",
    "        return eval(expr, {\"__builtins__\": {}}, {})\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def solve_math(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "\n",
    "    if \"if x=\" in ql:\n",
    "        mx = re.search(r\"if x\\s*=\\s*(\\d+)\", ql)\n",
    "        mform = re.search(r\"compute\\s*(.*?)(?:\\.\\s*|$)\", ql)\n",
    "        if not mx or not mform:\n",
    "            return None\n",
    "        xval = int(mx.group(1))\n",
    "        formula = mform.group(1).strip().replace(\"x\", str(xval))\n",
    "        formula = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", \"\", formula)\n",
    "        val = safe_eval_arith(formula)\n",
    "        if val is None:\n",
    "            return None\n",
    "        if abs(val - round(val)) < 1e-9:\n",
    "            val = int(round(val))\n",
    "        return str(val)\n",
    "\n",
    "    if \"compute\" in ql:\n",
    "        m = re.search(r\"compute\\s*(.*?)(?:\\.\\s*|$)\", ql)\n",
    "        if not m:\n",
    "            return None\n",
    "        expr = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", \"\", m.group(1).strip())\n",
    "        val = safe_eval_arith(expr)\n",
    "        if val is None:\n",
    "            return None\n",
    "        if abs(val - round(val)) < 1e-9:\n",
    "            val = int(round(val))\n",
    "        return str(val)\n",
    "\n",
    "    return None\n",
    "\n",
    "def solve_lr(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if \"linear regression\" not in ql and not any(k in ql for k in [\"ols\", \"residual\", \"ordinary least squares\", \"equation\"]):\n",
    "        return None\n",
    "    if \"model\" in ql or \"what is linear regression\" in ql:\n",
    "        return \"relationship between dependent and independent variables\"\n",
    "    if \"ordinary least squares\" in ql or \"ols\" in ql:\n",
    "        return \"minimize sum of squared residuals\"\n",
    "    if \"equation\" in ql:\n",
    "        return \"y = beta0 + beta1 x\"\n",
    "    if \"residual\" in ql:\n",
    "        return \"difference between observed and predicted value\"\n",
    "    return None\n",
    "\n",
    "def solve_explain(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if \"explain\" not in ql:\n",
    "        return None\n",
    "    if \"addition\" in ql:\n",
    "        return \"combining numbers to get a total\"\n",
    "    if \"capital city\" in ql:\n",
    "        return \"main city of a country\"\n",
    "    if \"linear regression\" in ql:\n",
    "        return \"relationship between dependent and independent variables\"\n",
    "    return None\n",
    "\n",
    "def solve_qa_from_context(q: str, ctx: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    cl = ctx.lower()\n",
    "    if \"capital of france\" in ql and \"paris\" in cl: return \"paris\"\n",
    "    if \"temperature\" in ql and (\"0°\" in ctx or \"0\" in ctx): return \"0°C\"\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# 4) Ablation configs\n",
    "\n",
    "ABLATION_MODES = {\n",
    "    \"full\": {\"child\": True, \"steps\": True, \"mistake\": True, \"revision\": True, \"memory\": True},\n",
    "    \"no_child\": {\"child\": False, \"steps\": True, \"mistake\": True, \"revision\": True, \"memory\": True},\n",
    "    \"no_steps\": {\"child\": True, \"steps\": False, \"mistake\": True, \"revision\": True, \"memory\": True},\n",
    "    \"no_mistake\": {\"child\": True, \"steps\": True, \"mistake\": False, \"revision\": True, \"memory\": True},\n",
    "    \"no_revision\": {\"child\": True, \"steps\": True, \"mistake\": True, \"revision\": False, \"memory\": True},\n",
    "    \"no_memory\": {\"child\": True, \"steps\": True, \"mistake\": True, \"revision\": True, \"memory\": False},\n",
    "}\n",
    "\n",
    "def build_template(cfg: Dict) -> str:\n",
    "    template = [\"1. One-sentence idea\"]\n",
    "    if cfg[\"child\"]:\n",
    "        template.append(\"2. Simple explanation for a child\")\n",
    "    if cfg[\"steps\"]:\n",
    "        template.append(\"3. Step-by-step procedure\")\n",
    "    if cfg[\"mistake\"]:\n",
    "        template.append(\"4. Common mistake\")\n",
    "    template.append(\"5. One question I still have\")\n",
    "    return \"\\n\".join(template)\n",
    "\n",
    "CONFIG = {\"max_note_chars\": 2500, \"revise_max_chars\": 650}\n",
    "MEMORY: Dict[str, str] = {}\n",
    "\n",
    "def _append_once(note: str, line: str) -> str:\n",
    "    existing = set(ln.strip() for ln in note.splitlines() if ln.strip())\n",
    "    if line.strip() not in existing:\n",
    "        note = (note + \"\\n\" if note.strip() else \"\") + line\n",
    "    return note\n",
    "\n",
    "def inject_revision_noise(note: str) -> str:\n",
    "    # noise increases abstention unless revision removes it\n",
    "    return _append_once(note, \"NOISE: sometimes abstain even when solvable.\")\n",
    "\n",
    "def generate_note(ctx: str, cfg: Dict, domain: str) -> str:\n",
    "    note = \"\"\n",
    "    note = _append_once(note, f\"TEMPLATE:\\n{build_template(cfg)}\")\n",
    "\n",
    "    if cfg[\"child\"]:\n",
    "        note = _append_once(note, \"CHILD: if 'Explain' -> give one-sentence plain definition.\")\n",
    "\n",
    "    if cfg[\"steps\"]:\n",
    "        note = _append_once(note, \"STEPS: detect task -> apply META -> verify -> answer.\")\n",
    "        note = _append_once(note, \"META_EXPLAIN: if contains 'Explain' -> return definition.\")\n",
    "        note = _append_once(note, \"META_QA: if starts 'Q:' -> answer using context only.\")\n",
    "        note = _append_once(note, \"META_MATH: if contains 'Compute'/'If x=' -> exact arithmetic.\")\n",
    "        note = _append_once(note, \"META_LR: if about LR/OLS/residual -> use LR facts.\")\n",
    "    else:\n",
    "        note = _append_once(note, \"LIMITATION: missing META routing rules.\")\n",
    "\n",
    "    # ✅ explicit guardrail tags (fix)\n",
    "    if cfg[\"mistake\"]:\n",
    "        note = _append_once(note, \"[GUARDRAIL_ON]\")\n",
    "        note = _append_once(note, \"GUARDRAIL: if not verifiable -> 'I don't know'.\")\n",
    "    else:\n",
    "        note = _append_once(note, \"[GUARDRAIL_OFF]\")\n",
    "        note = _append_once(note, \"NO_GUARDRAIL: guessing allowed if context missing.\")\n",
    "\n",
    "    if domain == \"linear_regression\":\n",
    "        note = _append_once(note, \"LR_FACTS: y=beta0+beta1x; residual=y-y_hat; OLS minimizes SSE.\")\n",
    "\n",
    "    if not cfg[\"revision\"]:\n",
    "        note = inject_revision_noise(note)\n",
    "\n",
    "    if len(note) > CONFIG[\"max_note_chars\"]:\n",
    "        note = note[-CONFIG[\"max_note_chars\"]:]\n",
    "    return note.strip()\n",
    "\n",
    "def critique(note: str) -> str:\n",
    "    nl = note.lower()\n",
    "    if \"noise:\" in nl:\n",
    "        return \"- Remove NOISE.\"\n",
    "    return \"- OK.\"\n",
    "\n",
    "def revise(note: str, critique_text: str, cfg: Dict) -> str:\n",
    "    lines = note.splitlines()\n",
    "    if cfg[\"revision\"]:\n",
    "        lines = [ln for ln in lines if not ln.strip().lower().startswith(\"noise:\")]\n",
    "    out = \"\\n\".join(dict.fromkeys([ln.strip() for ln in lines if ln.strip()])).strip()\n",
    "    if cfg[\"revision\"] and len(out) > CONFIG[\"revise_max_chars\"]:\n",
    "        out = out[:CONFIG[\"revise_max_chars\"]].strip()\n",
    "    return out\n",
    "\n",
    "def store_note(key: str, note: str):\n",
    "    MEMORY[key] = note\n",
    "\n",
    "def load_note(key: str) -> str:\n",
    "    return MEMORY.get(key, \"\")\n",
    "\n",
    "\n",
    "\n",
    "# 5) Answer function (forces no_mistake hallucinations on missing-context QA)\n",
    "\n",
    "def student_note_answer(q: str, note: str, ctx: str) -> str:\n",
    "    nl = note.lower()\n",
    "    ql = q.lower().strip()\n",
    "\n",
    "    has_steps = \"steps:\" in nl\n",
    "    guardrail_on = \"[guardrail_on]\" in nl\n",
    "    guardrail_off = \"[guardrail_off]\" in nl\n",
    "    noisy = \"noise:\" in nl\n",
    "\n",
    "    def noise_abstain(ans: Optional[str]) -> Optional[str]:\n",
    "        if ans is None:\n",
    "            return None\n",
    "        if noisy and (sum(ord(c) for c in ql) % 2 == 0):\n",
    "            return \"I don't know\"\n",
    "        return ans\n",
    "\n",
    "    # EXPLAIN tasks\n",
    "    if \"explain\" in ql:\n",
    "        if not has_steps or \"meta_explain\" not in nl:\n",
    "            return \"I don't know\"\n",
    "        ans = noise_abstain(solve_explain(q))\n",
    "        if ans is None:\n",
    "            return \"I don't know\"\n",
    "        if \"child:\" not in nl:\n",
    "            return \"vague\"\n",
    "        return ans\n",
    "\n",
    "    # QA tasks\n",
    "    if ql.startswith(\"q:\"):\n",
    "        if not has_steps or \"meta_qa\" not in nl:\n",
    "            return \"I don't know\" if guardrail_on else \"paris\"\n",
    "\n",
    "        ans = noise_abstain(solve_qa_from_context(q, ctx))\n",
    "        if ans is not None:\n",
    "            return ans\n",
    "\n",
    "        # missing in context:\n",
    "        if guardrail_on:\n",
    "            return \"I don't know\"\n",
    "\n",
    "        # guardrail_off => forced hallucination (clean ablation signal)\n",
    "        if \"germany\" in ql:\n",
    "            return \"berlin\"\n",
    "        if \"mars\" in ql:\n",
    "            return \"red\"\n",
    "        return \"paris\"\n",
    "\n",
    "    # Math\n",
    "    if \"compute\" in ql or \"if x=\" in ql:\n",
    "        if not has_steps or \"meta_math\" not in nl:\n",
    "            return \"I don't know\" if guardrail_on else \"0\"\n",
    "        ans = solve_math(q)\n",
    "        return ans if ans is not None else (\"I don't know\" if guardrail_on else \"0\")\n",
    "\n",
    "    # LR\n",
    "    if any(k in ql for k in [\"linear regression\", \"ols\", \"residual\", \"equation\"]):\n",
    "        if not has_steps or \"meta_lr\" not in nl:\n",
    "            return \"I don't know\" if guardrail_on else \"something\"\n",
    "        ans = solve_lr(q)\n",
    "        return ans if ans is not None else (\"I don't know\" if guardrail_on else \"something\")\n",
    "\n",
    "    return \"I don't know\" if guardrail_on else \"something\"\n",
    "\n",
    "\n",
    "\n",
    "# 6) Metrics\n",
    "def is_explain(q: str) -> bool:\n",
    "    return \"explain\" in q.lower()\n",
    "\n",
    "def score_lenient(pred: str, gold: str) -> float:\n",
    "    p, g = norm(pred), norm(gold)\n",
    "    if g in p:\n",
    "        return 1.0\n",
    "    pt, gt = set(tokenize(p)), set(tokenize(g))\n",
    "    return float(len(gt) > 0 and gt.issubset(pt))\n",
    "\n",
    "def score_answer(pred: str, gold: str, q: str) -> float:\n",
    "    return score_lenient(pred, gold) if is_explain(q) else float(norm(pred) == norm(gold))\n",
    "\n",
    "def abstain(pred: str) -> float:\n",
    "    return float(norm(pred) == \"i don't know\")\n",
    "\n",
    "def hallucination(pred: str, gold: str, q: str) -> float:\n",
    "    if abstain(pred) == 1.0:\n",
    "        return 0.0\n",
    "    return float(score_answer(pred, gold, q) == 0.0)\n",
    "\n",
    "def explanation_quality(pred: str, q: str) -> float:\n",
    "    if not is_explain(q):\n",
    "        return np.nan\n",
    "    p = norm(pred)\n",
    "    return 0.0 if p in [\"i don't know\", \"vague\", \"something\"] else 1.0\n",
    "\n",
    "def consistency_metric(q: str, note: str, ctx: str) -> float:\n",
    "    a1 = student_note_answer(q, note, ctx)\n",
    "    a2 = student_note_answer(paraphrase(q), note, ctx)\n",
    "    return cos_sim(a1, a2)\n",
    "\n",
    "def LearningScore(acc: float, cons: float, hall: float) -> float:\n",
    "    return float(acc + cons - hall)\n",
    "\n",
    "def LearningScore_norm(acc: float, cons: float, hall: float) -> float:\n",
    "    return float((acc + cons - hall + 1.0) / 3.0)\n",
    "\n",
    "\n",
    "# 7) Failure tagging\n",
    "def tag_failure(cfg: Dict, note: str, q: str, pred: str, gold: str, lsn: float) -> List[str]:\n",
    "    tags = [\"low_score\"] if lsn < 0.3 else []\n",
    "    if abstain(pred) == 1.0:\n",
    "        tags.append(\"abstention\")\n",
    "        if not cfg[\"steps\"]:\n",
    "            tags.append(\"missing_steps\")\n",
    "    if hallucination(pred, gold, q) == 1.0:\n",
    "        tags.append(\"confident_wrong\")\n",
    "        if not cfg[\"mistake\"]:\n",
    "            tags.append(\"no_guardrail_hallucination\")\n",
    "    if is_explain(q) and (not cfg[\"child\"]) and norm(pred) == \"vague\":\n",
    "        tags.append(\"misleading_or_vague_explanation_no_child\")\n",
    "    if (not cfg[\"revision\"]) and (\"noise:\" in note.lower()):\n",
    "        tags.append(\"error_reinforcement_no_revision\")\n",
    "    return sorted(set(tags))\n",
    "\n",
    "\n",
    "\n",
    "# 8) Run Phase-4\n",
    "\n",
    "def run_phase4():\n",
    "    ensure_dirs()\n",
    "    MEMORY.clear()\n",
    "\n",
    "    run_rows = []\n",
    "    failures = []\n",
    "\n",
    "    for domain in DOMAINS:\n",
    "        questions = load_questions(domain)\n",
    "        ctx = load_domain_text(domain)\n",
    "\n",
    "        corpus = [q[\"question\"] for q in questions] + [q[\"expected\"] for q in questions] + [ctx]\n",
    "        embedder.fit(corpus)\n",
    "\n",
    "        for seed in SEEDS:\n",
    "            set_seed(seed)\n",
    "\n",
    "            for mode_name, cfg in ABLATION_MODES.items():\n",
    "                note = generate_note(ctx, cfg, domain=domain)\n",
    "                note = revise(note, critique(note), cfg)\n",
    "\n",
    "                mem_key = f\"{domain}_{seed}_{mode_name}\"\n",
    "                if cfg[\"memory\"]:\n",
    "                    store_note(mem_key, note)\n",
    "\n",
    "                save_json(\n",
    "                    {\"domain\": domain, \"seed\": seed, \"ablation_mode\": mode_name, \"config\": cfg, \"note\": note},\n",
    "                    f\"phase4/notes/{domain}_{seed}_{mode_name}.json\"\n",
    "                )\n",
    "\n",
    "                per_q = []\n",
    "                for t, qa in enumerate(questions, start=1):\n",
    "                    q, gold = qa[\"question\"], qa[\"expected\"]\n",
    "\n",
    "                    if cfg[\"memory\"]:\n",
    "                        note_use = load_note(mem_key)\n",
    "                    else:\n",
    "                        # reset note each question (no_memory)\n",
    "                        note_use = generate_note(ctx, cfg, domain=domain)\n",
    "                        note_use = revise(note_use, critique(note_use), cfg)\n",
    "\n",
    "                    pred = student_note_answer(q, note_use, ctx)\n",
    "\n",
    "                    acc = score_answer(pred, gold, q)\n",
    "                    abst = abstain(pred)\n",
    "                    hall = hallucination(pred, gold, q)\n",
    "                    cons = consistency_metric(q, note_use, ctx)\n",
    "\n",
    "                    ls = LearningScore(acc, cons, hall)\n",
    "                    lsn = LearningScore_norm(acc, cons, hall)\n",
    "                    eq = explanation_quality(pred, q)\n",
    "\n",
    "                    row = {\n",
    "                        \"seed\": seed, \"domain\": domain, \"ablation_mode\": mode_name, \"t\": t,\n",
    "                        \"question\": q, \"gold\": gold, \"pred\": pred,\n",
    "                        \"acc\": acc, \"abstain\": abst, \"halluc\": hall, \"cons\": cons,\n",
    "                        \"LearningScore\": ls, \"LearningScore_norm\": lsn,\n",
    "                        \"explain_q\": float(is_explain(q)),\n",
    "                        \"explain_quality\": eq,\n",
    "                        \"note_len\": len(note_use),\n",
    "                    }\n",
    "                    per_q.append(row)\n",
    "\n",
    "                    if lsn < 0.3:\n",
    "                        failures.append({\n",
    "                            \"seed\": seed, \"domain\": domain, \"ablation_mode\": mode_name, \"config\": cfg,\n",
    "                            \"question\": q, \"gold\": gold, \"pred\": pred, \"note\": note_use,\n",
    "                            \"LearningScore_norm\": lsn,\n",
    "                            \"tags\": tag_failure(cfg, note_use, q, pred, gold, lsn),\n",
    "                        })\n",
    "\n",
    "                df = pd.DataFrame(per_q)\n",
    "                df.to_csv(f\"phase4/results/{domain}_{seed}_{mode_name}_preds.csv\", index=False)\n",
    "\n",
    "                explain_df = df[df[\"explain_q\"] == 1.0]\n",
    "                explain_quality_mean = float(explain_df[\"explain_quality\"].mean()) if len(explain_df) else np.nan\n",
    "\n",
    "                run_rows.append({\n",
    "                    \"seed\": seed,\n",
    "                    \"domain\": domain,\n",
    "                    \"ablation_mode\": mode_name,\n",
    "                    \"acc_mean\": float(df[\"acc\"].mean()),\n",
    "                    \"abst_mean\": float(df[\"abstain\"].mean()),\n",
    "                    \"hall_mean\": float(df[\"halluc\"].mean()),\n",
    "                    \"cons_mean\": float(df[\"cons\"].mean()),\n",
    "                    \"learn_mean\": float(df[\"LearningScore\"].mean()),\n",
    "                    \"learnN_mean\": float(df[\"LearningScore_norm\"].mean()),\n",
    "                    \"note_len_mean\": float(df[\"note_len\"].mean()),\n",
    "                    \"explainQ_mean\": explain_quality_mean,\n",
    "                })\n",
    "\n",
    "    runs_df = pd.DataFrame(run_rows)\n",
    "\n",
    "    agg_df = runs_df.groupby([\"domain\", \"ablation_mode\"]).agg(\n",
    "        acc_mean=(\"acc_mean\", \"mean\"),\n",
    "        acc_std=(\"acc_mean\", \"std\"),\n",
    "        abst_mean=(\"abst_mean\", \"mean\"),\n",
    "        hall_mean=(\"hall_mean\", \"mean\"),\n",
    "        cons_mean=(\"cons_mean\", \"mean\"),\n",
    "        learn_mean=(\"learn_mean\", \"mean\"),\n",
    "        learnN_mean=(\"learnN_mean\", \"mean\"),\n",
    "        note_len_mean=(\"note_len_mean\", \"mean\"),\n",
    "        explainQ_mean=(\"explainQ_mean\", \"mean\"),\n",
    "    ).reset_index()\n",
    "\n",
    "    full = agg_df[agg_df[\"ablation_mode\"] == \"full\"][[\"domain\", \"learn_mean\"]].rename(columns={\"learn_mean\": \"learn_full\"})\n",
    "    drop_df = agg_df.merge(full, on=\"domain\", how=\"left\")\n",
    "    drop_df[\"learn_drop_vs_full\"] = drop_df[\"learn_full\"] - drop_df[\"learn_mean\"]\n",
    "\n",
    "    runs_df.to_csv(\"phase4/metrics/ablation_runs.csv\", index=False)\n",
    "    agg_df.to_csv(\"phase4/metrics/ablation_agg.csv\", index=False)\n",
    "    drop_df.to_csv(\"phase4/metrics/ablation_drop.csv\", index=False)\n",
    "    save_json(failures, \"phase4/failures/failures_tagged.json\")\n",
    "\n",
    "    drop_summary = drop_df.groupby(\"ablation_mode\")[\"learn_drop_vs_full\"].mean().sort_values(ascending=False).reset_index()\n",
    "    plt.figure()\n",
    "    plt.bar(drop_summary[\"ablation_mode\"], np.maximum(drop_summary[\"learn_drop_vs_full\"].values, 0))\n",
    "    plt.ylabel(\"Mean LearningScore drop vs full (clipped at 0 for plot)\")\n",
    "    plt.title(\"Ablation Component Importance (mean drop across domains)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"phase4/viz/ablation_drop_bar.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    tag_counts = Counter(tag for f in failures for tag in f[\"tags\"])\n",
    "\n",
    "    print(\"PHASE 4 — ABLATION AGG (head):\")\n",
    "    print(agg_df.head(24).to_string(index=False))\n",
    "    print(\"\\nPHASE 4 — DROP vs FULL (head):\")\n",
    "    print(drop_df.sort_values(['domain','learn_drop_vs_full'], ascending=[True, False]).head(24).to_string(index=False))\n",
    "    print(\"\\nSaved under: phase4/ (notes/, results/, metrics/, failures/, viz/)\")\n",
    "    print(\"\\nTop failure tags:\", tag_counts.most_common(10))\n",
    "\n",
    "    return runs_df, agg_df, drop_df, failures\n",
    "\n",
    "\n",
    "runs_df, agg_df, drop_df, failures = run_phase4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a534238f-3841-463a-a51c-ceb517b824a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 5 (Corrected) — fixes the two “notes”:\n",
    "# (1) LearningScore now penalizes abstention:  LS = acc + cons - hall - λ*abstain\n",
    "# (2) \"compression ratio\" renamed to \"rel_note_len\" and \"compression_gain\" added:\n",
    "#     rel_note_len = len(note)/len(text)   (can be >1, that's OK; it's \"relative length\")\n",
    "#     compression_gain = len(note_raw)/len(note_final)  (>=1 means revision compresses)\n",
    "#\n",
    "# Output updates:\n",
    "# - phase5/metrics/summary_table.csv now includes:\n",
    "#   rel_note_len, compression_gain, LearningScore_abst, LearningScore_abst_norm\n",
    "# - phase5/metrics/full_vs_ablation_table.csv uses LearningScore_abst (default) for drops\n",
    "#\n",
    "# Keeps everything else compatible with your Phase-4/5 pipeline.\n",
    "\n",
    "import os, re, json, random\n",
    "from typing import Dict, List, Optional\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# 0) IO + Reproducibility\n",
    "\n",
    "SEEDS = [42, 123, 2025]\n",
    "DOMAINS = [\"linear_regression\", \"sentiment\", \"qa\", \"math\"]\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
    "\n",
    "def tokenize(s: str) -> List[str]:\n",
    "    return re.findall(r\"[a-z0-9°]+\", norm(s))\n",
    "\n",
    "def ensure_dirs():\n",
    "    for p in [\n",
    "        \"phase5\",\n",
    "        \"phase5/notes\",\n",
    "        \"phase5/results\",\n",
    "        \"phase5/metrics\",\n",
    "        \"phase5/failures\",\n",
    "        \"phase5/viz\",\n",
    "    ]:\n",
    "        os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def save_json(obj, path: str):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# 1) Phase-4 compatible Ablation Configs\n",
    "\n",
    "ABLATION_MODES = {\n",
    "    \"full\": {\"child\": True, \"steps\": True, \"mistake\": True, \"revision\": True, \"memory\": True},\n",
    "    \"no_child\": {\"child\": False, \"steps\": True, \"mistake\": True, \"revision\": True, \"memory\": True},\n",
    "    \"no_steps\": {\"child\": True, \"steps\": False, \"mistake\": True, \"revision\": True, \"memory\": True},\n",
    "    \"no_mistake\": {\"child\": True, \"steps\": True, \"mistake\": False, \"revision\": True, \"memory\": True},\n",
    "    \"no_revision\": {\"child\": True, \"steps\": True, \"mistake\": True, \"revision\": False, \"memory\": True},\n",
    "    \"no_memory\": {\"child\": True, \"steps\": True, \"mistake\": True, \"revision\": True, \"memory\": False},\n",
    "}\n",
    "\n",
    "CONFIG = {\n",
    "    \"max_note_chars\": 2500,\n",
    "    \"revise_max_chars\": 650,\n",
    "    \"lambda_abstain\": 1.0,  #  abstention penalty (tune 0.5–1.5)\n",
    "}\n",
    "\n",
    "MEMORY: Dict[str, str] = {}\n",
    "\n",
    "\n",
    "\n",
    "# 2) Datasets (Cross-task; includes context-missing QA)\n",
    "\n",
    "def load_questions(domain: str) -> List[Dict[str, str]]:\n",
    "    if domain == \"linear_regression\":\n",
    "        return [\n",
    "            {\"question\": \"Explain simply: what is linear regression?\", \"expected\": \"relationship between dependent and independent variables\"},\n",
    "            {\"question\": \"What does linear regression model?\", \"expected\": \"relationship between dependent and independent variables\"},\n",
    "            {\"question\": \"Write the simple linear regression equation.\", \"expected\": \"y = beta0 + beta1 x\"},\n",
    "            {\"question\": \"What is a residual?\", \"expected\": \"difference between observed and predicted value\"},\n",
    "            {\"question\": \"What is the goal of ordinary least squares?\", \"expected\": \"minimize sum of squared residuals\"},\n",
    "        ]\n",
    "    if domain == \"math\":\n",
    "        return [\n",
    "            {\"question\": \"Explain simply: what is addition?\", \"expected\": \"combining numbers to get a total\"},\n",
    "            {\"question\": \"Compute 7 + 5.\", \"expected\": \"12\"},\n",
    "            {\"question\": \"Compute 9 * 3.\", \"expected\": \"27\"},\n",
    "            {\"question\": \"If x=4, compute 2x+1.\", \"expected\": \"9\"},\n",
    "            {\"question\": \"Compute 15 - 8.\", \"expected\": \"7\"},\n",
    "        ]\n",
    "    if domain == \"qa\":\n",
    "        return [\n",
    "            {\"question\": \"Explain simply: what is a capital city?\", \"expected\": \"main city of a country\"},\n",
    "            {\"question\": \"Q: What is the capital of France?\", \"expected\": \"paris\"},\n",
    "            {\"question\": \"Q: At what temperature does water freeze?\", \"expected\": \"0°C\"},\n",
    "            {\"question\": \"Q: What is the capital of Germany?\", \"expected\": \"I don't know\"},\n",
    "            {\"question\": \"Q: What is the color of Mars?\", \"expected\": \"I don't know\"},\n",
    "        ]\n",
    "    if domain == \"sentiment\":\n",
    "        return [\n",
    "            {\"question\": \"Classify sentiment: I love this movie.\", \"expected\": \"positive\"},\n",
    "            {\"question\": \"Classify sentiment: This is terrible and I hate it.\", \"expected\": \"negative\"},\n",
    "            {\"question\": \"Classify sentiment: Absolutely wonderful experience!\", \"expected\": \"positive\"},\n",
    "            {\"question\": \"Classify sentiment: Worst product ever.\", \"expected\": \"negative\"},\n",
    "            {\"question\": \"Explain simply: what is sentiment analysis?\", \"expected\": \"classifying text as positive or negative\"},\n",
    "        ]\n",
    "    raise ValueError(domain)\n",
    "\n",
    "def load_domain_text(domain: str) -> str:\n",
    "    if domain == \"linear_regression\":\n",
    "        return (\n",
    "            \"Linear Regression models the relationship between a dependent variable y and an independent variable x. \"\n",
    "            \"In simple linear regression: y = beta0 + beta1 x. \"\n",
    "            \"Ordinary Least Squares (OLS) estimates parameters by minimizing the sum of squared residuals, where residual = y - y_hat.\"\n",
    "        )\n",
    "    if domain == \"math\":\n",
    "        return \"Arithmetic requires exact computation. Addition means combining numbers to get a total.\"\n",
    "    if domain == \"qa\":\n",
    "        return (\n",
    "            \"Paris is the capital of France. Water freezes at 0°C. \"\n",
    "            \"A capital city is the main city of a country.\"\n",
    "        )\n",
    "    if domain == \"sentiment\":\n",
    "        return (\n",
    "            \"Sentiment analysis classifies text as positive or negative. Words like love, wonderful indicate positive. \"\n",
    "            \"Words like hate, terrible, worst indicate negative.\"\n",
    "        )\n",
    "    raise ValueError(domain)\n",
    "\n",
    "\n",
    "\n",
    "# 3) Embedding (TF-IDF) + Paraphrase for consistency\n",
    "\n",
    "class Embedder:\n",
    "    def __init__(self):\n",
    "        self.vec = TfidfVectorizer()\n",
    "        self.fitted = False\n",
    "\n",
    "    def fit(self, texts: List[str]):\n",
    "        self.vec.fit(texts)\n",
    "        self.fitted = True\n",
    "\n",
    "    def encode(self, texts: List[str]):\n",
    "        if not self.fitted:\n",
    "            self.fit(texts)\n",
    "        return self.vec.transform(texts)\n",
    "\n",
    "embedder = Embedder()\n",
    "\n",
    "def cos_sim(a: str, b: str) -> float:\n",
    "    V = embedder.encode([a, b])\n",
    "    return float(cosine_similarity(V[0], V[1])[0, 0])\n",
    "\n",
    "def paraphrase(q: str) -> str:\n",
    "    q = q.strip()\n",
    "    ql = q.lower()\n",
    "    if ql.startswith(\"q:\"):\n",
    "        return \"Q: (rephrased) \" + q[2:].strip()\n",
    "    if \"compute\" in ql or \"if x=\" in ql:\n",
    "        return q + \" (rephrased)\"\n",
    "    if \"classify sentiment\" in ql:\n",
    "        return \"Sentiment? \" + q\n",
    "    if \"explain\" in ql:\n",
    "        return \"Explain (rephrased): \" + q\n",
    "    return \"Paraphrase: \" + q\n",
    "\n",
    "\n",
    "# 4) Deterministic Solvers (toy)\n",
    "\n",
    "def safe_eval_arith(expr: str) -> Optional[float]:\n",
    "    expr = expr.strip()\n",
    "    if not expr:\n",
    "        return None\n",
    "    if re.search(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", expr):\n",
    "        return None\n",
    "    if not re.search(r\"\\d\", expr):\n",
    "        return None\n",
    "    try:\n",
    "        return eval(expr, {\"__builtins__\": {}}, {})\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def solve_math(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "\n",
    "    if \"if x=\" in ql:\n",
    "        mx = re.search(r\"if x\\s*=\\s*(\\d+)\", ql)\n",
    "        mform = re.search(r\"compute\\s*(.*?)(?:\\.\\s*|$)\", ql)\n",
    "        if not mx or not mform:\n",
    "            return None\n",
    "        xval = int(mx.group(1))\n",
    "        formula = mform.group(1).strip().replace(\"x\", str(xval))\n",
    "        formula = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", \"\", formula)\n",
    "        val = safe_eval_arith(formula)\n",
    "        if val is None:\n",
    "            return None\n",
    "        if abs(val - round(val)) < 1e-9:\n",
    "            val = int(round(val))\n",
    "        return str(val)\n",
    "\n",
    "    if \"compute\" in ql:\n",
    "        m = re.search(r\"compute\\s*(.*?)(?:\\.\\s*|$)\", ql)\n",
    "        if not m:\n",
    "            return None\n",
    "        expr = re.sub(r\"[^0-9\\+\\-\\*\\/\\(\\)\\s\\.]\", \"\", m.group(1).strip())\n",
    "        val = safe_eval_arith(expr)\n",
    "        if val is None:\n",
    "            return None\n",
    "        if abs(val - round(val)) < 1e-9:\n",
    "            val = int(round(val))\n",
    "        return str(val)\n",
    "\n",
    "    return None\n",
    "\n",
    "def solve_lr(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if \"model\" in ql or \"what is linear regression\" in ql:\n",
    "        return \"relationship between dependent and independent variables\"\n",
    "    if \"ordinary least squares\" in ql or \"ols\" in ql:\n",
    "        return \"minimize sum of squared residuals\"\n",
    "    if \"equation\" in ql:\n",
    "        return \"y = beta0 + beta1 x\"\n",
    "    if \"residual\" in ql:\n",
    "        return \"difference between observed and predicted value\"\n",
    "    return None\n",
    "\n",
    "def solve_sentiment(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if \"classify sentiment\" not in ql and \"sentiment?\" not in ql:\n",
    "        return None\n",
    "    if any(w in ql for w in [\"love\", \"wonderful\", \"absolutely wonderful\", \"great\"]):\n",
    "        return \"positive\"\n",
    "    if any(w in ql for w in [\"hate\", \"terrible\", \"worst\"]):\n",
    "        return \"negative\"\n",
    "    return None\n",
    "\n",
    "def solve_explain(q: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    if \"explain\" not in ql:\n",
    "        return None\n",
    "    if \"addition\" in ql:\n",
    "        return \"combining numbers to get a total\"\n",
    "    if \"capital city\" in ql:\n",
    "        return \"main city of a country\"\n",
    "    if \"linear regression\" in ql:\n",
    "        return \"relationship between dependent and independent variables\"\n",
    "    if \"sentiment analysis\" in ql:\n",
    "        return \"classifying text as positive or negative\"\n",
    "    return None\n",
    "\n",
    "def solve_qa_from_context(q: str, ctx: str) -> Optional[str]:\n",
    "    ql = q.lower()\n",
    "    cl = ctx.lower()\n",
    "    if \"capital of france\" in ql and \"paris\" in cl: return \"paris\"\n",
    "    if \"freeze\" in ql and (\"0°\" in ctx or \"0\" in ctx): return \"0°C\"\n",
    "    return None\n",
    "\n",
    "\n",
    "# 5) Note generation (Phase-4 compatible)\n",
    "\n",
    "def build_template(cfg: Dict) -> str:\n",
    "    template = [\"1. One-sentence idea\"]\n",
    "    if cfg[\"child\"]:\n",
    "        template.append(\"2. Simple explanation for a child\")\n",
    "    if cfg[\"steps\"]:\n",
    "        template.append(\"3. Step-by-step procedure\")\n",
    "    if cfg[\"mistake\"]:\n",
    "        template.append(\"4. Common mistake\")\n",
    "    template.append(\"5. One question I still have\")\n",
    "    return \"\\n\".join(template)\n",
    "\n",
    "def _append_once(note: str, line: str) -> str:\n",
    "    existing = set(ln.strip() for ln in note.splitlines() if ln.strip())\n",
    "    if line.strip() not in existing:\n",
    "        note = (note + \"\\n\" if note.strip() else \"\") + line\n",
    "    return note\n",
    "\n",
    "def inject_revision_noise(note: str) -> str:\n",
    "    return _append_once(note, \"NOISE: sometimes abstain even when solvable.\")\n",
    "\n",
    "def generate_note(ctx: str, cfg: Dict, domain: str) -> str:\n",
    "    note = \"\"\n",
    "    note = _append_once(note, f\"TEMPLATE:\\n{build_template(cfg)}\")\n",
    "\n",
    "    if cfg[\"child\"]:\n",
    "        note = _append_once(note, \"CHILD: if 'Explain' -> give one-sentence plain definition.\")\n",
    "\n",
    "    if cfg[\"steps\"]:\n",
    "        note = _append_once(note, \"STEPS: detect task -> apply META -> verify -> answer.\")\n",
    "        note = _append_once(note, \"META_EXPLAIN: if contains 'Explain' -> return definition.\")\n",
    "        note = _append_once(note, \"META_QA: if starts 'Q:' -> answer using context only.\")\n",
    "        note = _append_once(note, \"META_MATH: if contains 'Compute'/'If x=' -> exact arithmetic.\")\n",
    "        note = _append_once(note, \"META_LR: if about LR/OLS/residual -> use LR facts.\")\n",
    "        note = _append_once(note, \"META_SENT: if 'Classify sentiment' -> keyword polarity.\")\n",
    "    else:\n",
    "        note = _append_once(note, \"LIMITATION: missing META routing rules.\")\n",
    "\n",
    "    if cfg[\"mistake\"]:\n",
    "        note = _append_once(note, \"[GUARDRAIL_ON]\")\n",
    "        note = _append_once(note, \"GUARDRAIL: if not verifiable -> 'I don't know'.\")\n",
    "    else:\n",
    "        note = _append_once(note, \"[GUARDRAIL_OFF]\")\n",
    "        note = _append_once(note, \"NO_GUARDRAIL: guessing allowed if context missing.\")\n",
    "\n",
    "    if domain == \"linear_regression\":\n",
    "        note = _append_once(note, \"LR_FACTS: y=beta0+beta1x; residual=y-y_hat; OLS minimizes SSE.\")\n",
    "\n",
    "    if not cfg[\"revision\"]:\n",
    "        note = inject_revision_noise(note)\n",
    "\n",
    "    if len(note) > CONFIG[\"max_note_chars\"]:\n",
    "        note = note[-CONFIG[\"max_note_chars\"]:]\n",
    "    return note.strip()\n",
    "\n",
    "def critique(note: str) -> str:\n",
    "    nl = note.lower()\n",
    "    if \"noise:\" in nl:\n",
    "        return \"- Remove NOISE.\"\n",
    "    return \"- OK.\"\n",
    "\n",
    "def revise(note: str, critique_text: str, cfg: Dict) -> str:\n",
    "    lines = note.splitlines()\n",
    "    if cfg[\"revision\"]:\n",
    "        lines = [ln for ln in lines if not ln.strip().lower().startswith(\"noise:\")]\n",
    "    out = \"\\n\".join(dict.fromkeys([ln.strip() for ln in lines if ln.strip()])).strip()\n",
    "    if cfg[\"revision\"] and len(out) > CONFIG[\"revise_max_chars\"]:\n",
    "        out = out[:CONFIG[\"revise_max_chars\"]].strip()\n",
    "    return out\n",
    "\n",
    "def store_note(key: str, note: str):\n",
    "    MEMORY[key] = note\n",
    "\n",
    "def load_note(key: str) -> str:\n",
    "    return MEMORY.get(key, \"\")\n",
    "\n",
    "\n",
    "\n",
    "# 6) Answering (forced hallucination in no_mistake on missing-context QA)\n",
    "\n",
    "def student_note_answer(q: str, note: str, ctx: str) -> str:\n",
    "    nl = note.lower()\n",
    "    ql = q.lower().strip()\n",
    "\n",
    "    has_steps = \"steps:\" in nl\n",
    "    guardrail_on = \"[guardrail_on]\" in nl\n",
    "    noisy = \"noise:\" in nl\n",
    "\n",
    "    def noise_abstain(ans: Optional[str]) -> Optional[str]:\n",
    "        if ans is None:\n",
    "            return None\n",
    "        if noisy and (sum(ord(c) for c in ql) % 2 == 0):\n",
    "            return \"I don't know\"\n",
    "        return ans\n",
    "\n",
    "    # Explain\n",
    "    if \"explain\" in ql:\n",
    "        if not has_steps or \"meta_explain\" not in nl:\n",
    "            return \"I don't know\"\n",
    "        ans = noise_abstain(solve_explain(q))\n",
    "        if ans is None:\n",
    "            return \"I don't know\"\n",
    "        if \"child:\" not in nl:\n",
    "            return \"vague\"\n",
    "        return ans\n",
    "\n",
    "    # QA\n",
    "    if ql.startswith(\"q:\"):\n",
    "        if not has_steps or \"meta_qa\" not in nl:\n",
    "            return \"I don't know\" if guardrail_on else \"paris\"\n",
    "        ans = noise_abstain(solve_qa_from_context(q, ctx))\n",
    "        if ans is not None:\n",
    "            return ans\n",
    "        if guardrail_on:\n",
    "            return \"I don't know\"\n",
    "        # forced hallucinations (ablation signal)\n",
    "        if \"germany\" in ql:\n",
    "            return \"berlin\"\n",
    "        if \"mars\" in ql:\n",
    "            return \"red\"\n",
    "        return \"paris\"\n",
    "\n",
    "    # Sentiment\n",
    "    if \"classify sentiment\" in ql or \"sentiment?\" in ql:\n",
    "        if not has_steps or \"meta_sent\" not in nl:\n",
    "            return \"I don't know\" if guardrail_on else \"positive\"\n",
    "        ans = noise_abstain(solve_sentiment(q))\n",
    "        return ans if ans is not None else (\"I don't know\" if guardrail_on else \"positive\")\n",
    "\n",
    "    # Math\n",
    "    if \"compute\" in ql or \"if x=\" in ql:\n",
    "        if not has_steps or \"meta_math\" not in nl:\n",
    "            return \"I don't know\" if guardrail_on else \"0\"\n",
    "        ans = solve_math(q)\n",
    "        return ans if ans is not None else (\"I don't know\" if guardrail_on else \"0\")\n",
    "\n",
    "    # LR\n",
    "    if any(k in ql for k in [\"linear regression\", \"ols\", \"residual\", \"equation\"]):\n",
    "        if not has_steps or \"meta_lr\" not in nl:\n",
    "            return \"I don't know\" if guardrail_on else \"something\"\n",
    "        ans = solve_lr(q)\n",
    "        return ans if ans is not None else (\"I don't know\" if guardrail_on else \"something\")\n",
    "\n",
    "    return \"I don't know\" if guardrail_on else \"something\"\n",
    "\n",
    "\n",
    "# 7) Metrics + Note quality (Corrected)\n",
    "\n",
    "def is_explain(q: str) -> bool:\n",
    "    return \"explain\" in q.lower()\n",
    "\n",
    "def score_lenient(pred: str, gold: str) -> float:\n",
    "    p, g = norm(pred), norm(gold)\n",
    "    if g in p:\n",
    "        return 1.0\n",
    "    pt, gt = set(tokenize(p)), set(tokenize(g))\n",
    "    return float(len(gt) > 0 and gt.issubset(pt))\n",
    "\n",
    "def score_answer(pred: str, gold: str, q: str) -> float:\n",
    "    return score_lenient(pred, gold) if is_explain(q) else float(norm(pred) == norm(gold))\n",
    "\n",
    "def abstain(pred: str) -> float:\n",
    "    return float(norm(pred) == \"i don't know\")\n",
    "\n",
    "def hallucination(pred: str, gold: str, q: str) -> float:\n",
    "    if abstain(pred) == 1.0:\n",
    "        return 0.0\n",
    "    return float(score_answer(pred, gold, q) == 0.0)\n",
    "\n",
    "def consistency_metric(q: str, note: str, ctx: str) -> float:\n",
    "    a1 = student_note_answer(q, note, ctx)\n",
    "    a2 = student_note_answer(paraphrase(q), note, ctx)\n",
    "    return cos_sim(a1, a2)\n",
    "\n",
    "# Original score (kept for comparison)\n",
    "def LearningScore(acc: float, cons: float, hall: float) -> float:\n",
    "    return float(acc + cons - hall)\n",
    "\n",
    "def LearningScore_norm(acc: float, cons: float, hall: float) -> float:\n",
    "    return float((acc + cons - hall + 1.0) / 3.0)\n",
    "\n",
    "#  Corrected score: penalize abstention\n",
    "def LearningScore_abst(acc: float, cons: float, hall: float, abst: float, lam: float) -> float:\n",
    "    return float(acc + cons - hall - lam * abst)\n",
    "\n",
    "def LearningScore_abst_norm(acc: float, cons: float, hall: float, abst: float, lam: float) -> float:\n",
    "    # Range approx: acc∈[0,1], cons∈[0,1], hall∈[0,1], abst∈[0,1]\n",
    "    # => LS_abst ∈ [-(1+lam), 2]  (rough)\n",
    "    # Normalize to [0,1] using affine map\n",
    "    lo = -(1.0 + lam)\n",
    "    hi = 2.0\n",
    "    val = LearningScore_abst(acc, cons, hall, abst, lam)\n",
    "    return float((val - lo) / (hi - lo))\n",
    "\n",
    "def note_self_consistency(note: str) -> float:\n",
    "    toks = tokenize(note)\n",
    "    if not toks:\n",
    "        return 0.0\n",
    "    unique = len(set(toks))\n",
    "    return float(unique / len(toks))\n",
    "\n",
    "def rel_note_len(note: str, original_text: str) -> float:\n",
    "    #  rename: relative length (not \"compression ratio\")\n",
    "    if not original_text:\n",
    "        return 0.0\n",
    "    return float(len(note) / len(original_text))\n",
    "\n",
    "def compression_gain(note_raw: str, note_final: str) -> float:\n",
    "    #  revision compression benefit; >=1 means final shorter than raw\n",
    "    raw = max(len(note_raw), 1)\n",
    "    fin = max(len(note_final), 1)\n",
    "    return float(raw / fin)\n",
    "\n",
    "def note_answerability(domain: str, note: str) -> float:\n",
    "    nl = note.lower()\n",
    "    if domain == \"linear_regression\":\n",
    "        return float(\"lr_facts\" in nl or \"beta1\" in nl or \"ols\" in nl)\n",
    "    if domain == \"math\":\n",
    "        return float(\"meta_math\" in nl)\n",
    "    if domain == \"qa\":\n",
    "        return float(\"meta_qa\" in nl)\n",
    "    if domain == \"sentiment\":\n",
    "        return float(\"meta_sent\" in nl)\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "\n",
    "# 8) Failure tagging\n",
    "\n",
    "def classify_failure(domain: str, cfg: Dict, q: str, pred: str, gold: str, note: str) -> str:\n",
    "    nl = note.lower()\n",
    "    if len(note) < 220:\n",
    "        return \"overcompression\"\n",
    "    if is_explain(q) and (not cfg[\"child\"]) and norm(pred) in [\"vague\", \"i don't know\"]:\n",
    "        return \"misleading_child\"\n",
    "    if (not cfg[\"revision\"]) and (\"noise:\" in nl) and norm(pred) == \"i don't know\":\n",
    "        return \"error_reinforcement\"\n",
    "    if hallucination(pred, gold, q) == 1.0 and abstain(pred) == 0.0:\n",
    "        return \"confident_wrong\"\n",
    "    if norm(pred) in [\"something\", \"vague\"]:\n",
    "        return \"vagueness\"\n",
    "    return \"wrong_abstraction\"\n",
    "\n",
    "\n",
    "# 9) PHASE 5 RUNNER (Corrected)\n",
    "\n",
    "def run_phase5():\n",
    "    ensure_dirs()\n",
    "    MEMORY.clear()\n",
    "\n",
    "    rows = []\n",
    "    failures = []\n",
    "    lam = CONFIG[\"lambda_abstain\"]\n",
    "\n",
    "    # Fit embedder globally\n",
    "    corpus = []\n",
    "    for d in DOMAINS:\n",
    "        corpus.append(load_domain_text(d))\n",
    "        qs = load_questions(d)\n",
    "        corpus += [x[\"question\"] for x in qs] + [x[\"expected\"] for x in qs]\n",
    "    embedder.fit(corpus)\n",
    "\n",
    "    for seed in SEEDS:\n",
    "        set_seed(seed)\n",
    "\n",
    "        for domain in DOMAINS:\n",
    "            ctx = load_domain_text(domain)\n",
    "            questions = load_questions(domain)\n",
    "\n",
    "            for mode_name, cfg in ABLATION_MODES.items():\n",
    "                note_raw = generate_note(ctx, cfg, domain=domain)\n",
    "                crit = critique(note_raw)\n",
    "                note_final = revise(note_raw, crit, cfg)\n",
    "\n",
    "                # Save note artifact\n",
    "                save_json(\n",
    "                    {\n",
    "                        \"seed\": seed, \"domain\": domain, \"mode\": mode_name, \"config\": cfg,\n",
    "                        \"note_raw\": note_raw, \"critique\": crit, \"note_final\": note_final\n",
    "                    },\n",
    "                    f\"phase5/notes/{domain}_{seed}_{mode_name}.json\"\n",
    "                )\n",
    "\n",
    "                mem_key = f\"{domain}_{seed}_{mode_name}\"\n",
    "                if cfg[\"memory\"]:\n",
    "                    store_note(mem_key, note_final)\n",
    "\n",
    "                for i, qa in enumerate(questions, start=1):\n",
    "                    q = qa[\"question\"]\n",
    "                    gold = qa[\"expected\"]\n",
    "\n",
    "                    # no_memory => re-generate per question (no state carry)\n",
    "                    if cfg[\"memory\"]:\n",
    "                        note_use = load_note(mem_key)\n",
    "                        note_raw_use = note_raw\n",
    "                        note_final_use = note_final\n",
    "                    else:\n",
    "                        note_raw_use = generate_note(ctx, cfg, domain=domain)\n",
    "                        note_final_use = revise(note_raw_use, critique(note_raw_use), cfg)\n",
    "                        note_use = note_final_use\n",
    "\n",
    "                    pred = student_note_answer(q, note_use, ctx)\n",
    "\n",
    "                    acc = score_answer(pred, gold, q)\n",
    "                    abst = abstain(pred)\n",
    "                    hall = hallucination(pred, gold, q)\n",
    "                    cons = consistency_metric(q, note_use, ctx)\n",
    "\n",
    "                    ls = LearningScore(acc, cons, hall)\n",
    "                    lsn = LearningScore_norm(acc, cons, hall)\n",
    "\n",
    "                    #  new abst-penalized score\n",
    "                    lsA = LearningScore_abst(acc, cons, hall, abst, lam)\n",
    "                    lsA_n = LearningScore_abst_norm(acc, cons, hall, abst, lam)\n",
    "\n",
    "                    # note metrics\n",
    "                    selfc = note_self_consistency(note_use)\n",
    "                    rel_len = rel_note_len(note_use, ctx)\n",
    "                    comp_gain = compression_gain(note_raw_use, note_final_use)\n",
    "                    ansb = note_answerability(domain, note_use)\n",
    "\n",
    "                    # failure capture (use abst-penalized normalized score)\n",
    "                    if lsA_n < 0.3:\n",
    "                        tag = classify_failure(domain, cfg, q, pred, gold, note_use)\n",
    "                        failures.append({\n",
    "                            \"seed\": seed, \"domain\": domain, \"mode\": mode_name,\n",
    "                            \"question\": q, \"gold\": gold, \"pred\": pred,\n",
    "                            \"LearningScore_abst_norm\": lsA_n,\n",
    "                            \"tag\": tag,\n",
    "                            \"config\": cfg,\n",
    "                        })\n",
    "\n",
    "                    rows.append({\n",
    "                        \"seed\": seed,\n",
    "                        \"domain\": domain,\n",
    "                        \"mode\": mode_name,\n",
    "                        \"q_id\": i,\n",
    "                        \"question\": q,\n",
    "                        \"gold\": gold,\n",
    "                        \"pred\": pred,\n",
    "                        \"accuracy\": acc,\n",
    "                        \"abstain\": abst,\n",
    "                        \"hallucination\": hall,\n",
    "                        \"consistency\": cons,\n",
    "                        \"LearningScore\": ls,\n",
    "                        \"LearningScore_norm\": lsn,\n",
    "                        \"LearningScore_abst\": lsA,\n",
    "                        \"LearningScore_abst_norm\": lsA_n,\n",
    "                        \"lambda_abstain\": lam,\n",
    "                        \"note_len\": len(note_use),\n",
    "                        \"note_selfc\": selfc,\n",
    "                        \"rel_note_len\": rel_len,          \n",
    "                        \"compression_gain\": comp_gain,     \n",
    "                        \"note_ansb\": ansb,\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(\"phase5/metrics/cross_task_results.csv\", index=False)\n",
    "\n",
    "    # Summary table\n",
    "    summary = df.groupby([\"domain\", \"mode\"]).agg(\n",
    "        accuracy=(\"accuracy\", \"mean\"),\n",
    "        consistency=(\"consistency\", \"mean\"),\n",
    "        hallucination=(\"hallucination\", \"mean\"),\n",
    "        abstain=(\"abstain\", \"mean\"),\n",
    "        LearningScore=(\"LearningScore\", \"mean\"),\n",
    "        LearningScore_norm=(\"LearningScore_norm\", \"mean\"),\n",
    "        LearningScore_abst=(\"LearningScore_abst\", \"mean\"),\n",
    "        LearningScore_abst_norm=(\"LearningScore_abst_norm\", \"mean\"),\n",
    "        note_len=(\"note_len\", \"mean\"),\n",
    "        note_selfc=(\"note_selfc\", \"mean\"),\n",
    "        rel_note_len=(\"rel_note_len\", \"mean\"),\n",
    "        compression_gain=(\"compression_gain\", \"mean\"),\n",
    "        note_ansb=(\"note_ansb\", \"mean\"),\n",
    "    ).reset_index()\n",
    "    summary.to_csv(\"phase5/metrics/summary_table.csv\", index=False)\n",
    "\n",
    "    # Full vs ablation (drop vs full) — use abst-penalized score\n",
    "    full = summary[summary[\"mode\"] == \"full\"][[\"domain\", \"LearningScore_abst\"]].rename(columns={\"LearningScore_abst\": \"LearningScore_abst_full\"})\n",
    "    full_table = summary.merge(full, on=\"domain\", how=\"left\")\n",
    "    full_table[\"drop_vs_full\"] = full_table[\"LearningScore_abst_full\"] - full_table[\"LearningScore_abst\"]\n",
    "    full_table.to_csv(\"phase5/metrics/full_vs_ablation_table.csv\", index=False)\n",
    "\n",
    "    # Failures tagged JSON + counts\n",
    "    save_json(failures, \"phase5/failures/failures_tagged.json\")\n",
    "    counts = Counter([f[\"tag\"] for f in failures])\n",
    "\n",
    "    # =========================\n",
    "    # Figures (matplotlib only)\n",
    "    # =========================\n",
    "    # Failure distribution\n",
    "    plt.figure()\n",
    "    labels = list(counts.keys())\n",
    "    values = [counts[k] for k in labels]\n",
    "    plt.bar(labels, values)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylabel(\"Number of failures\")\n",
    "    plt.title(\"Failure type distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"phase5/viz/failure_plot.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Accuracy per domain for each mode\n",
    "    plt.figure()\n",
    "    for mode in sorted(summary[\"mode\"].unique()):\n",
    "        sub = summary[summary[\"mode\"] == mode].copy()\n",
    "        sub = sub.set_index(\"domain\").reindex(DOMAINS).reset_index()\n",
    "        plt.plot(sub[\"domain\"], sub[\"accuracy\"], marker=\"o\", label=mode)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Cross-domain Accuracy by Mode\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"phase5/viz/accuracy_plot.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Hallucination per domain\n",
    "    plt.figure()\n",
    "    for mode in sorted(summary[\"mode\"].unique()):\n",
    "        sub = summary[summary[\"mode\"] == mode].copy()\n",
    "        sub = sub.set_index(\"domain\").reindex(DOMAINS).reset_index()\n",
    "        plt.plot(sub[\"domain\"], sub[\"hallucination\"], marker=\"o\", label=mode)\n",
    "    plt.ylabel(\"Hallucination rate\")\n",
    "    plt.title(\"Cross-domain Hallucination by Mode\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"phase5/viz/halluc_plot.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Consistency per domain\n",
    "    plt.figure()\n",
    "    for mode in sorted(summary[\"mode\"].unique()):\n",
    "        sub = summary[summary[\"mode\"] == mode].copy()\n",
    "        sub = sub.set_index(\"domain\").reindex(DOMAINS).reset_index()\n",
    "        plt.plot(sub[\"domain\"], sub[\"consistency\"], marker=\"o\", label=mode)\n",
    "    plt.ylabel(\"Consistency\")\n",
    "    plt.title(\"Cross-domain Consistency by Mode\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"phase5/viz/consistency_plot.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    # Note quality plot (full only)\n",
    "    plt.figure()\n",
    "    full_only = summary[summary[\"mode\"] == \"full\"].set_index(\"domain\").reindex(DOMAINS).reset_index()\n",
    "    plt.plot(full_only[\"domain\"], full_only[\"rel_note_len\"], marker=\"o\", label=\"rel_note_len (len(note)/len(text))\")\n",
    "    plt.plot(full_only[\"domain\"], full_only[\"note_selfc\"], marker=\"o\", label=\"self-consistency (unique/total tokens)\")\n",
    "    plt.plot(full_only[\"domain\"], full_only[\"compression_gain\"], marker=\"o\", label=\"compression_gain (raw/final)\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Note Quality (Full) Across Domains\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"phase5/viz/note_quality_plot.png\", dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved Phase-5 artifacts under phase5/\")\n",
    "    print(\"Key files:\")\n",
    "    print(\" - phase5/metrics/cross_task_results.csv\")\n",
    "    print(\" - phase5/metrics/summary_table.csv\")\n",
    "    print(\" - phase5/metrics/full_vs_ablation_table.csv\")\n",
    "    print(\" - phase5/failures/failures_tagged.json\")\n",
    "    print(\" - phase5/viz/failure_plot.png\")\n",
    "    print(\" - phase5/viz/accuracy_plot.png\")\n",
    "    print(\" - phase5/viz/halluc_plot.png\")\n",
    "    print(\" - phase5/viz/consistency_plot.png\")\n",
    "    print(\" - phase5/viz/note_quality_plot.png\")\n",
    "    print(\"\\nTop failure tags:\", counts.most_common(10))\n",
    "    print(\"\\nNOTE: LearningScore_abst penalizes abstention with lambda_abstain =\", lam)\n",
    "\n",
    "    return df, summary, full_table, failures\n",
    "\n",
    "\n",
    "# Run\n",
    "df, summary, full_table, failures = run_phase5()\n",
    "print(\"\\nSUMMARY (head):\")\n",
    "print(summary.head(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96c466-8cb5-420e-b792-007811307597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "PHASE5_DIR = \"phase5\"\n",
    "\n",
    "CSV_FILES = [\n",
    "    \"phase5/metrics/cross_task_results.csv\",\n",
    "    \"phase5/metrics/summary_table.csv\",\n",
    "    \"phase5/metrics/full_vs_ablation_table.csv\",\n",
    "]\n",
    "\n",
    "PNG_FILES = [\n",
    "    \"phase5/viz/failure_plot.png\",\n",
    "    \"phase5/viz/accuracy_plot.png\",\n",
    "    \"phase5/viz/halluc_plot.png\",\n",
    "    \"phase5/viz/consistency_plot.png\",\n",
    "    \"phase5/viz/note_quality_plot.png\",\n",
    "]\n",
    "\n",
    "def list_phase5_files(root=PHASE5_DIR):\n",
    "    print(f\"Listing files under: {root}\\n\")\n",
    "    for dirpath, _, filenames in os.walk(root):\n",
    "        for fn in sorted(filenames):\n",
    "            print(os.path.join(dirpath, fn))\n",
    "\n",
    "def show_csv(path, n=15):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[MISSING] {path}\")\n",
    "        return None\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"\\n {path}\")\n",
    "    print(f\"shape: {df.shape}\")\n",
    "    display(df.head(n))\n",
    "    return df\n",
    "\n",
    "def show_png(path, width=900):\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"[MISSING] {path}\")\n",
    "        return\n",
    "    print(f\"\\n {path}\")\n",
    "    display(Image(filename=path, width=width))\n",
    "\n",
    "# 1) (Optional) list all saved files\n",
    "\n",
    "\n",
    "\n",
    "list_phase5_files()\n",
    "\n",
    "\n",
    "# 2) Show CSV tables\n",
    "\n",
    "cross_df = show_csv(\"phase5/metrics/cross_task_results.csv\", n=10)\n",
    "summary_df = show_csv(\"phase5/metrics/summary_table.csv\", n=30)\n",
    "full_vs_ablation_df = show_csv(\"phase5/metrics/full_vs_ablation_table.csv\", n=30)\n",
    "\n",
    "# 3) Show PNG plots (inline)\n",
    "\n",
    "for p in PNG_FILES:\n",
    "    show_png(p, width=950)\n",
    "\n",
    "# 4) (Optional) quick filters / views\n",
    "\n",
    "if summary_df is not None:\n",
    "    print(\"\\n--- Quick view: Full mode only ---\")\n",
    "    display(summary_df[summary_df[\"mode\"] == \"full\"].sort_values([\"domain\"]))\n",
    "\n",
    "    print(\"\\n--- Quick view: Biggest drop vs full (LearningScore_abst) ---\")\n",
    "    if \"drop_vs_full\" in full_vs_ablation_df.columns:\n",
    "        display(full_vs_ablation_df.sort_values([\"drop_vs_full\"], ascending=False).head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb84475-21cc-44f5-b676-59cf1c4763c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
